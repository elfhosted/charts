# This controls whether our automation will auto-release this to stable during the daily maint window
safeToRelease: true

# This section just makes images easier to update / parse
tooling_image: &tooling_image ghcr.io/geek-cookbook/tooling:focal-20230801@sha256:daaf77687540a2d7bfd5802eda1d79cb5a0b4e26444a9577d43efe0ce537c60c

# And this makes the media / rclone mounts tidier.
rclonecustoma: &rclonecustoma
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: custom-a
  mountPath: /storage/custom-a
rclonea: &rclonea
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: rclone-a
  mountPath: /storage/rclone-a
rcloneb: &rcloneb
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: rclone-b
  mountPath: /storage/rclone-b
rclonec: &rclonec
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: rclone-c
  mountPath: /storage/rclone-c
gdrivea: &gdrivea
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: gdrive-a
  mountPath: /storage/gdrive-a
gdriveb: &gdriveb
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: gdrive-b
  mountPath: /storage/gdrive-b
gdrivec: &gdrivec
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: gdrive-c
  mountPath: /storage/gdrive-c
gdrived: &gdrived
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: gdrive-d
  mountPath: /storage/gdrive-d
rclonegdriveencrypteda: &rclonegdriveencrypteda
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: gdrive-encrypted-a
  mountPath: /storage/gdrive-encrypted-a  
rclonegdriveencryptedb: &rclonegdriveencryptedb
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: gdrive-encrypted-b
  mountPath: /storage/gdrive-encrypted-b  
rclonegdriveencryptedc: &rclonegdriveencryptedc
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: gdrive-encrypted-c
  mountPath: /storage/gdrive-encrypted-c  
onedrivea: &onedrivea
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: onedrive-a
  mountPath: /storage/onedrive-a
rclonemountwebdava: &rclonemountwebdava
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: webdav-a
  mountPath: /storage/webdav-a
rclonemountssha: &rclonemountssha
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: ssh-a
  mountPath: /storage/ssh-a
rclonemountsshb: &rclonemountsshb
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: ssh-b
  mountPath: /storage/ssh-b
rclonemountsshc: &rclonemountsshc
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: ssh-c
  mountPath: /storage/ssh-c
webdavb: &webdavb
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: webdav-b
  mountPath: /storage/webdav-b
webdavc: &webdavc
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: webdav-c
  mountPath: /storage/webdav-c
storageboxa: &storageboxa
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: storagebox-a
  mountPath: /storage/storagebox-a
  subaccount: false
storageboxb: &storageboxb
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: storagebox-b
  mountPath: /storage/storagebox-b
  subaccount: false
storageboxc: &storageboxc
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: storagebox-c
  mountPath: /storage/storagebox-c
  subaccount: false
rclonestorageboxencrypteda: &rclonestorageboxencrypteda
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: storagebox-encrypted-a
  mountPath: /storage/storagebox-encrypted-a
  subaccount: false  
rclonestorageboxencryptedb: &rclonestorageboxencryptedb
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: storagebox-encrypted-b
  mountPath: /storage/storagebox-encrypted-b
  subaccount: false    
rclonestorageboxencryptedc: &rclonestorageboxencryptedc
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: storagebox-encrypted-c
  mountPath: /storage/storagebox-encrypted-c
  subaccount: false  
premiumize: &premiumize
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: premiumize
  mountPath: /storage/premiumize
b2: &b2
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: b2
  mountPath: /storage/b2
smbmounta: &smbmounta
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: smbmount-a
  mountPath: /storage/smbmount-a
smbmountb: &smbmountb
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: smbmount-b
  mountPath: /storage/smbmount-b
smbmountc: &smbmountc
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: smbmount-c
  mountPath: /storage/smbmount-c
rclonesmbencrypteda: &rclonesmbencrypteda
  enabled: false
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: smb-encrypted-a
  mountPath: /storage/smb-encrypted-a  
elfstorage: &elfstorage
  enabled: true # always enabled
  type: custom
  volumeSpec:
    persistentVolumeClaim:
      claimName: elfstorage
  mountPath: /storage/elfstorage
tmp: &tmp # use ephemeral volumes
  enabled: true
  type: custom
  mountPath: /tmp
  volumeSpec:
    ephemeral:
      volumeClaimTemplate:
        spec:
          accessModes: [ "ReadWriteOnce" ]
          storageClassName: "topolvm-provisioner-thin"
          resources:
            requests:
              storage: 1Gi  

              
# This simplfies the process of adding all the optional mounts to every app
appmounts: &appmounts
  tmp: *tmp
  elfstorage: *elfstorage
  rclonecustoma: *rclonecustoma
  rclonea: *rclonea
  rcloneb: *rcloneb
  rclonec: *rclonec
  gdrivea: *gdrivea
  gdriveb: *gdriveb
  gdrivec: *gdrivec
  gdrived: *gdrived
  rclonegdriveencrypteda: *rclonegdriveencrypteda
  rclonegdriveencryptedb: *rclonegdriveencryptedb
  rclonegdriveencryptedc: *rclonegdriveencryptedc    
  onedrivea: *onedrivea
  rclonemountwebdava: *rclonemountwebdava
  rclonemountssha: *rclonemountssha
  storageboxa: *storageboxa
  storageboxb: *storageboxb
  storageboxc: *storageboxc
  rclonestorageboxencrypteda: *rclonestorageboxencrypteda
  rclonestorageboxencryptedb: *rclonestorageboxencryptedb
  rclonestorageboxencryptedc: *rclonestorageboxencryptedc    
  premiumize: *premiumize
  b2: *b2
  smbmounta: *smbmounta
  smbmountb: *smbmountb
  smbmountc: *smbmountc
  rclonesmbencrypteda: *rclonesmbencrypteda

# The entire bootstrap sidecar/additionalcontainer
default_resources: &default_resources
  requests:
    cpu: 10m
    memory: 1Mi
  limits:
    cpu: 1
    memory: 1024Mi # just a safety net against bugs!

default_securitycontext: &default_securitycontext
  seccompProfile:
    type: RuntimeDefault
  readOnlyRootFilesystem: true
  allowPrivilegeEscalation: false
  runAsUser: 568
  runAsGroup: 568
  capabilities:
    drop:
    - ALL

# We use this to provide env not only to bootstrap, but also to the torrent clients which use elfvpn
# it's necessary since the wireguard configs are in S3
bootstrap_env: &bootstrap_env
- name: AWS_ACCESS_KEY_ID
  valueFrom:
    secretKeyRef:
      key: access-key-id
      name: b2-elfhosted-config-ro
- name: AWS_SECRET_ACCESS_KEY
  valueFrom:
    secretKeyRef:
      key: secret-key
      name: b2-elfhosted-config-ro
- name: S3_ENDPOINT_URL
  value: https://s3.us-west-000.backblazeb2.com
- name: K8S_APP_NAME
  valueFrom:
    fieldRef:
      fieldPath: metadata.labels['app.kubernetes.io/name']
- name: ELF_APP_NAME
  valueFrom:
    fieldRef:
      fieldPath: metadata.labels['app.elfhosted.com/name']

bootstrap-migrate-db: &bootstrap_migrate_db
  - name: migrate-database
    image: *tooling_image
    imagePullPolicy: IfNotPresent
    command:
    - /bin/bash
    - -c
    - |
      set -e

      if [[ ! -f /config/i-am-migrated ]]
      then
        if [[ ! -z "$(ls -A /config-hdd)" ]]
        then
          echo "Migrating from /config-hdd/..."
          time cp /config-hdd/* /config/ -rfpv
          touch /config/i-am-migrated
        fi
      fi
    volumeMounts:
    - mountPath: /config
      name: data
      subPath: database
    - mountPath: /config-hdd
      name: confighdd
      subPath: database
    env: *bootstrap_env
    resources: *default_resources
    securityContext: *default_securitycontext
    
bootstrap: &bootstrap
  image: *tooling_image
  imagePullPolicy: IfNotPresent
  command:
  - /bin/bash
  - -c
  - |
    set -e

    # Allows us to use app.elfhosted.com/name, but fall back to app.kubernetes.io/name if the former doesn't exist
    if [[ -z "$ELF_APP_NAME" ]]; then
      ELF_APP_NAME=$K8S_APP_NAME
    fi

    # look for commands - we match specific names in order of least-destructive
    TIMESTAMP_NOW=$(date +%s)
    if [[ -f /etc/elfbot/pause ]]; then
      TIMESTAMP_COMMAND=$(cat /etc/elfbot/pause)
      TIMESTAMP_DIFF=$((TIMESTAMP_NOW-TIMESTAMP_COMMAND))
      if [[ $TIMESTAMP_DIFF -lt 600 ]]; then
        COMMAND=pause
      fi
    fi

    # If no command is set, then move onto the next possibility
    if [[ -f /etc/elfbot/backup && -z "$COMMAND" ]]; then
      TIMESTAMP_COMMAND=$(cat /etc/elfbot/backup)
      TIMESTAMP_DIFF=$((TIMESTAMP_NOW-TIMESTAMP_COMMAND))
      if [[ $TIMESTAMP_DIFF -lt 600 ]]; then
        COMMAND=backup
      fi
    fi

    # If no command is set, then move onto the next possibility
    if [[ -f /etc/elfbot/reset && -z "$COMMAND" ]]; then
      TIMESTAMP_COMMAND=$(cat /etc/elfbot/reset)
      TIMESTAMP_DIFF=$((TIMESTAMP_NOW-TIMESTAMP_COMMAND))
      if [[ $TIMESTAMP_DIFF -lt 600 ]]; then
        COMMAND=reset
      fi
    fi

    case $COMMAND in

      "pause")
        echo "Recent pause command found, sleeping 5m.."
        sleep 300
        ;;

      "reset")
        echo "Recent reset command found, resetting"
        rm -rf /config/*
        ;;

      "backup")
        echo "Recent backup command found, backing up to /storage/elfstorage/backup/${ELF_APP_NAME}-${TIMESTAMP}"
        mkdir -p /storage/elfstorage/backup
        TIMESTAMP=$(printf '%(%Y-%m-%d--%H-%M)T\n' -1)
        cp -rfp /config /storage/elfstorage/backup/$ELF_APP_NAME-$TIMESTAMP
        ;;

    esac

    if [[ ! -f /config/i-am-bootstrapped ]]
    then
      echo "Bootstrapping from goldilocks config..."
      s5cmd sync s3://elfhosted-config/goldilocks/$ELF_APP_NAME/* /config/
      touch /config/i-am-bootstrapped
    fi

  volumeMounts:
  - mountPath: /etc/elfbot
    name: elfbot
  - mountPath: /config
    name: config
  - mountPath: /storage/elfstorage
    name: elfstorage
  env: *bootstrap_env
  resources: *default_resources
  securityContext: *default_securitycontext

# Eventually we'll remove the old one, and rename this to bootstrap
bootstrap_ssd: &bootstrap_ssd
  image: *tooling_image
  imagePullPolicy: IfNotPresent
  command:
  - /bin/bash
  - -c
  - |
    set -e

    # Allows us to use app.elfhosted.com/name, but fall back to app.kubernetes.io/name if the former doesn't exist
    if [[ -z "$ELF_APP_NAME" ]]; then
      ELF_APP_NAME=$K8S_APP_NAME
    fi

    # look for commands - we match specific names in order of least-destructive
    TIMESTAMP_NOW=$(date +%s)
    if [[ -f /etc/elfbot/pause ]]; then
      TIMESTAMP_COMMAND=$(cat /etc/elfbot/pause)
      TIMESTAMP_DIFF=$((TIMESTAMP_NOW-TIMESTAMP_COMMAND))
      if [[ $TIMESTAMP_DIFF -lt 600 ]]; then
        COMMAND=pause
      fi
    fi

    # If no command is set, then move onto the next possibility
    if [[ -f /etc/elfbot/backup && -z "$COMMAND" ]]; then
      TIMESTAMP_COMMAND=$(cat /etc/elfbot/backup)
      TIMESTAMP_DIFF=$((TIMESTAMP_NOW-TIMESTAMP_COMMAND))
      if [[ $TIMESTAMP_DIFF -lt 600 ]]; then
        COMMAND=backup
      fi
    fi

    # If no command is set, then move onto the next possibility
    if [[ -f /etc/elfbot/reset && -z "$COMMAND" ]]; then
      TIMESTAMP_COMMAND=$(cat /etc/elfbot/reset)
      TIMESTAMP_DIFF=$((TIMESTAMP_NOW-TIMESTAMP_COMMAND))
      if [[ $TIMESTAMP_DIFF -lt 600 ]]; then
        COMMAND=reset
      fi
    fi

    case $COMMAND in

      "pause")
        echo "Recent pause command found, sleeping 5m.."
        sleep 300
        ;;

      "reset")
        echo "Recent reset command found, resetting"
        rm -rf /config/*
        ;;

      "backup")
        echo "Recent backup command found, backing up to /storage/elfstorage/backup/${ELF_APP_NAME}-${TIMESTAMP}"
        mkdir -p /storage/elfstorage/backup
        TIMESTAMP=$(printf '%(%Y-%m-%d--%H-%M)T\n' -1)
        cp -rfp /config /storage/elfstorage/backup/$ELF_APP_NAME-$TIMESTAMP
        ;;

    esac

    if [[ ! -f /config/i-am-migrated ]]
    then
      if [[ ! -z "$(ls -A /config-hdd)" ]]
      then
        echo "Migrating from /config-hdd/..."
        time cp /config-hdd/* /config/ -rfpv
        touch /config/i-am-migrated
      fi
    fi
  

    if [[ ! -f /config/i-am-bootstrapped ]]
    then
      echo "Bootstrapping from goldilocks config..."
      s5cmd sync s3://elfhosted-config/goldilocks/$ELF_APP_NAME/* /config/
      touch /config/i-am-bootstrapped
    fi
  volumeMounts:
  - mountPath: /etc/elfbot
    name: elfbot
  - mountPath: /config
    name: config
  - mountPath: /config-hdd
    name: confighdd
  - mountPath: /storage/elfstorage
    name: elfstorage
  env: *bootstrap_env
  resources: *default_resources
  securityContext: *default_securitycontext

# This lets users buy blocks of 1TB storage, and add it to their 100Gi
elfstoragetb:
  quantity: 0
# And this lets a user buy a bundle (different SKU), and then still add more elfstorage later
elfstoragetbbundled:
  quantity: 0

themepark:
  theme: default # the default themegarden theme

# provide a default
userId: 1

# our VPN loadbalancerIP
torrentLoadBalancerIP: 10.0.42.101

# these are the "exposed" services which allow users to override SSO
# by themselves, they do nothing, but they allow us to selectively disable
# SSO on ingressroutes, or to use non-standard API keys in Homer
radarrexposed:
  enabled: false
  apikey: 041776c8d5f74bf295aa486d9d51c33a
radarr4kexposed:
  enabled: false
  apikey: 7da5d4ba79804527b78a78b68c7a0781
sonarrexposed:
  enabled: false
  apikey: a6f1c7d07fab4be49c5c1cb545f85a76
sonarr4kexposed:
  enabled: false
  apikey: e4f93c115169484bbed19821f7ac8e49
lidarrexposed:
  enabled: false
  apikey: 0e68e28531a249659737513d3102bfe9
readarrexposed:
  enabled: false
  apikey: 74b033ff59964011b8a32c014fdb9b68
readarraudioexposed:
  enabled: false
  apikey: 8496cefe2c6b46ee921e18caddf6a943
prowlarrexposed:
  enabled: false
  apikey: c53bc3bd17c645c3a457e5342a02cd66
bazarrexposed:
  enabled: false
  apikey: 94ab8212a12378fa5333cbf75a3c0390
bazarr4kexposed:
  enabled: false
  apikey: 393bda5f898886a2b87413e6452313af
qbittorrentexposed:
  enabled: false
delugeexposed:
  enabled: false
rutorrentexposed:
  enabled: false
sabnzbdexposed:
  enabled: false
  apikey: 8flkbru7ncdps3dzzgk48q2msz41m4on
nzbgetexposed:
  enabled: false
mylarrexposed:
  enabled: false
  apikey: 0f97f6a7f352c63eb43fcb7e53ea9d8f

uptimekumacustomdomain:
  enabled: false
mattermostcustomdomain:
  enabled: false
vaultwardencustomdomain:
  enabled: false

rutorrentgluetun: &rutorrent
  enabled: false
  sso:
    enabled: true
  automountServiceAccountToken: false
  image:
      repository: ghcr.io/geek-cookbook/rutorrent
      tag: 4.2.9-0.9.8-0.13.8@sha256:4cb85f96f0945630ebac1f4c72fc38584846eb1acfbb4a26f91b3a45303bb82a
  priorityClassName: tenant-bulk
  podLabels:
    app.elfhosted.com/name: rutorrent
    app.elfhosted.com/class: bulk
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,rutorrent-config,rutorrent-gluetun-config,elfbot-rutorrent" # Reload the deployment every time the yaml config changes
  securityContext:
    # runAsUser: 568 # enforced in env vars
    # runAsGroup: 568
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false
  envFrom:
  - configMapRef:
      name: elfbot-rutorrent
      optional: true 
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists

  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    nodeTaintsPolicy: Honor
    labelSelector: 
      matchLabels: 
        app.elfhosted.com/class: bulk

  # we need the injected initcontainer to run as root, so we can't change the pod-level uid/gid
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    # runAsUser: 568 # s6's fault
    # runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  persistence:
    <<: *appmounts
    tmp:
      enabled: true
      type: custom
      mountPath: /tmp
      volumeSpec:
        ephemeral:
          volumeClaimTemplate:
            spec:
              accessModes: [ "ReadWriteOnce" ]
              storageClassName: "topolvm-provisioner-thin"
              resources:
                requests:
                  storage: 1000Gi          
    config:
      enabled: true
      type: custom
      mountPath: /data/rtorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rutorrent-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-rutorrent
          optional: true
    shared:
      enabled: true
      mountPath: /shared
      type: emptyDir
      volumeSpec:
        medium: Memory
    port-range: # Used for dynamic port-forwarding
      enabled: true
      type: emptyDir
      mountPath: /port-range
      sizeLimit: 1Gi
    custom-rtlocal:
      enabled: "true"
      mountPath: "/.rtlocal.rc-elfhosted"
      subPath: ".rtlocal.rc-elfhosted"
      type: "custom"
      volumeSpec:
        configMap:
          name: rutorrent-config
    custom-rtorrentrc:
      enabled: "true"
      mountPath: "/.rtorrent.rc-elfhosted"
      subPath: ".rtorrent.rc-elfhosted"
      type: "custom"
      volumeSpec:
        configMap:
          name: rutorrent-config
    custom-s6-init-05:
      enabled: "true"
      mountPath: "/etc/cont-init.d/05-apply-elfhosted-config.sh"
      subPath: "05-apply-elfhosted-config.sh"
      type: "custom"
      volumeSpec:
        configMap:
          name: rutorrent-config
          defaultMode: 0755
    custom-s6-init-06:
      enabled: "true"
      mountPath: "/etc/cont-init.d/02-wait-for-vpn.sh"
      subPath: "02-wait-for-vpn.sh"
      type: "custom"
      volumeSpec:
        configMap:
          name: rutorrent-config
          defaultMode: 0755
    custom-s6-init-07:
      enabled: "true"
      mountPath: "/etc/cont-init.d/03-set-inbound-port.sh"
      subPath: "03-set-inbound-port.sh "
      type: "custom"
      volumeSpec:
        configMap:
          name: rutorrent-config
          defaultMode: 0755
    dante-config:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: dante-config    
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: false # necessary for probes, but probes aren't working with vpn addon currently
  resources:
    requests:
      cpu: 100m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1200Mi
  env:
    # -- Set the container timezone
    PUID: 568
    GUID: 568
    RUTORRENT_PORT: 8080 # necessary for health checks
    # S6_READ_ONLY_ROOT: 1 # this seems to break rutorrent :(
    WAIT_FOR_VPN: "true"
    PORT_FILE: /data/rtorrent/forwarded-port
    WAN_IP_CMD: 'curl -s ifconfig.me'
  initContainers:
    bootstrap: *bootstrap
  addons:
    vpn: &rutorrent_addons_vpn
      enabled: true
      type: gluetun
      gluetun:
        image:
          repository: docker.io/qmcgaw/gluetun
          tag: pr-1543 # See https://github.com/qdm12/gluetun/issues/1488
      securityContext:
        runAsUser: 0
        capabilities:
          add:
            - NET_ADMIN
            - SYS_MODULE
      envFrom:
      - configMapRef:
          name: rutorrent-gluetun-config
      additionalVolumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /storage/elfstorage
        name: elfstorage
      config: # We have to set this to null so that we can override with our own config

      # The scripts that get run when the VPN connection opens/closes are defined here.
      # The default scripts will write a string to represent the current connection state to a file.
      # Our qBittorrent image has a feature that can wait for this file to contain the word 'connected' before actually starting the application.
      scripts:
        up: |-
          #!/bin/bash
          echo "connected" > /shared/vpnstatus

        down: |-
          #!/bin/bash
          echo "disconnected" > /shared/vpnstatus

rutorrentpia:
  <<: *rutorrent
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,rutorrent-config,rutorrent-pia-config,elfbot-rutorrent" # Reload the deployment every time the yaml config changes
  addons:
    vpn:
      <<: *rutorrent_addons_vpn
      gluetun:
        image:
          repository: thrnz/docker-wireguard-pia
          tag: latest
      envFrom:
      - configMapRef:
          name: rutorrent-pia-config
  additionalContainers:
    # Use this to provied proxied access to arrs
    dante:
      image: ghcr.io/geek-cookbook/dante:v1.4.3
      env: *bootstrap_env
      securityContext: *default_securitycontext      
      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /etc/sockd.conf
        name: dante-config
        subPath: sockd.conf
    mam-helper:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /usr/bin/dumb-init
      - /bin/bash
      - -c
      - |
        set -e
        set -x

        echo "Waiting for VPN to be connected..."
        while ! grep -s -q "connected" /shared/vpnstatus; do
            echo "VPN not connected"
            sleep 2
        done
        echo "VPN Connected, processing cookies..."
        
        # If we have a cookie already, try to use it
        if [[ -f /config/mam/saved.cookies ]]; then
          curl -c /config/mam/saved.cookies -b /config/mam/saved.cookies https://t.myanonamouse.net/json/dynamicSeedbox.php  -o /config/mam/mam_id-curl-output.log
        fi

        # Now whether that worked or not, look for /config/mam/mam_id
        mkdir -p /config/mam
        while [ 1 ]; do
          if [[ -f /config/mam/mam_id ]]; then
            curl -c /config/mam/saved.cookies -b "mam_id=$(cat /config/mam/mam_id)" https://t.myanonamouse.net/json/dynamicSeedbox.php -o /config/mam/mam_id-curl-output.log
            mv /config/mam/mam_id /config/mam/mam_id_processed
          fi
          sleep 1m
        done
      volumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /shared
        name: shared        
      resources: *default_resources
      securityContext: *default_securitycontext

        
delugegluetun: &deluge
  enabled: false
  podLabels:
    app.elfhosted.com/name: deluge
    app.elfhosted.com/class: bulk
  sso:
    enabled: true
  automountServiceAccountToken: false
  image:
    repository: ghcr.io/geek-cookbook/deluge
    tag: 2.1.1@sha256:448324e342c47020e4e9fbc236282ceb80ebebd7934a486a6f1e487a7e4034bf
  priorityClassName: tenant-bulk
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    nodeTaintsPolicy: Honor
    labelSelector: 
      matchLabels: 
        app.elfhosted.com/class: bulk
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true

  # we need the injected initcontainer to run as root, so we can't change the pod-level uid/gid
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-deluge,deluge-gluetun-config"
  persistence:
    <<: *appmounts
    tmp:
      enabled: true
      type: custom
      mountPath: /tmp
      volumeSpec:
        ephemeral:
          volumeClaimTemplate:
            spec:
              accessModes: [ "ReadWriteOnce" ]
              storageClassName: "topolvm-provisioner-thin"
              resources:
                requests:
                  storage: 1000Gi         
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-deluge-ssd
    shared:
      enabled: true
      mountPath: /shared
      type: emptyDir
      volumeSpec:
        medium: Memory
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-deluge
          optional: true
    elfscripts:
      enabled: "true"
      mountPath: "/elfscripts/"
      type: "custom"
      volumeSpec:
        configMap:
          name: deluge-elfscripts
          defaultMode: 0755
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: false # necessary for probes, but probes aren't working with vpn addon currently
  env:
    # -- Set the container timezone
    TZ: UTC
    PUID: 568
    PGID: 568
    DELUGE_LOGLEVEL: "info"
  envFrom:
  - configMapRef:
      name: elfbot-deluge
      optional: true    
  extraEnvVars:
  - name: PORT_FILE
    valueFrom:
      configMapKeyRef:
        name: deluge-gluetun-config
        key: PORT_FILE
    optional: true
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      envFrom:
      - configMapRef:
          name: elfhosted-user-config
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /config/deluge/torrent_files

        # Setup autobrr access to daemon
        grep -q autobrr /config/auth || echo 'autobrr:c7RJKKt#KBcM5Z?a:10' >> /config/auth

        JQ_FILTER=".listen_random_port=false"
        JQ_FILTER="${JQ_FILTER} | .pre_allocate_storage=false"
        JQ_FILTER="${JQ_FILTER} | .stop_seed_ratio=2"
        JQ_FILTER="${JQ_FILTER} | .cache_size=52428"
        JQ_FILTER="${JQ_FILTER} | .share_ratio_limit=2"
        JQ_FILTER="${JQ_FILTER} | .stop_seed_at_ratio=true"

        jq "${JQ_FILTER}" /config/core.conf > /config/core-new.conf
        cp /config/core-new.conf /config/core.conf

        # # Avoid session timeouts
        # sed -i  "s/session_timeout:\".*/session_timeout\": 99999,/" /config/web.conf
      volumeMounts:
      - mountPath: /config
        name: config
      env: *bootstrap_env
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 100m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1200Mi
  addons:
    vpn: &deluge_addons_vpn
      enabled: true
      type: gluetun
      gluetun:
        image:
          repository: docker.io/qmcgaw/gluetun
          tag: pr-1543 # See https://github.com/qdm12/gluetun/issues/1488
      securityContext:
        runAsUser: 0
        capabilities:
          add:
            - NET_ADMIN
            - SYS_MODULE
      envFrom:
      - configMapRef:
          name: deluge-gluetun-config
      additionalVolumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /storage/elfstorage
        name: elfstorage
      config: # We have to set this to null so that we can override with our own config

      # The scripts that get run when the VPN connection opens/closes are defined here.
      # The default scripts will write a string to represent the current connection state to a file.
      # Our qBittorrent image has a feature that can wait for this file to contain the word 'connected' before actually starting the application.
      scripts:
        up: |-
          #!/bin/bash
          echo "connected" > /shared/vpnstatus

        down: |-
          #!/bin/bash
          echo "disconnected" > /shared/vpnstatus
  additionalContainers:
    deluge-web:
      image: ghcr.io/geek-cookbook/deluge:2.1.1@sha256:448324e342c47020e4e9fbc236282ceb80ebebd7934a486a6f1e487a7e4034bf
      command:
      - /usr/bin/deluge-web
      - -L
      - info
      - -d
      - -c
      - /config
      volumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /tmp
        name: tmp
      env:
        PYTHON_EGG_CACHE: /tmp/.cache

delugepia:
  <<: *deluge
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,deluge-config,deluge-pia-config,elfbot-deluge" # Reload the deployment every time the yaml config changes
  addons:
    vpn:
      <<: *deluge_addons_vpn
      gluetun:
        image:
          repository: thrnz/docker-wireguard-pia
          tag: latest
      envFrom:
      - configMapRef:
          name: deluge-pia-config
  additionalContainers:
    deluge-web:
      image: ghcr.io/geek-cookbook/deluge:2.1.1@sha256:448324e342c47020e4e9fbc236282ceb80ebebd7934a486a6f1e487a7e4034bf
      command:
      - /usr/bin/deluge-web
      - -L
      - info
      - -d
      - -c
      - /config
      volumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /tmp
        name: tmp
      env:
        PYTHON_EGG_CACHE: /tmp/.cache
    # Use this to provied proxied access to arrs
    dante:
      image: ghcr.io/geek-cookbook/dante:v1.4.3
      env: *bootstrap_env
      securityContext: *default_securitycontext   
      volumeMounts:
      - mountPath: /tmp
        name: tmp          

qbittorrentgluetun: &qbittorrent
  podLabels:
    app.elfhosted.com/name: qbittorrent
    app.elfhosted.com/class: bulk
  enabled: false
  sso:
    enabled: true
  automountServiceAccountToken: false
  image:
    registry: ghcr.io
    repository: geek-cookbook/qbittorrent
    tag: 4.6.1@sha256:2fc1e17d1e41396ce550a9491882d0d12898d233443c3683a4305acc4a9f7760
  priorityClassName: tenant-bulk
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    nodeTaintsPolicy: Honor
    labelSelector: 
      matchLabels: 
        app.elfhosted.com/class: bulk
  securityContext:
    runAsUser: 568
    runAsGroup: 568
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # doesn't seem to work well with entrypoint

  # we need the injected initcontainer to run as root, so we can't change the pod-level uid/gid
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-qbittorrent,qbittorrent-gluetun-config"
  persistence:
    <<: *appmounts
    tmp:
      enabled: true
      type: custom
      mountPath: /tmp
      volumeSpec:
        ephemeral:
          volumeClaimTemplate:
            spec:
              accessModes: [ "ReadWriteOnce" ]
              storageClassName: "topolvm-provisioner-thin"
              resources:
                requests:
                  storage: 1000Gi       
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-qbittorrent-ssd
    shared:
      enabled: true
      mountPath: /shared
      type: emptyDir
      volumeSpec:
        medium: Memory
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-qbittorrent
          optional: true
    elfscripts:
      enabled: "true"
      mountPath: "/elfscripts/"
      type: "custom"
      volumeSpec:
        configMap:
          name: qbittorrent-elfscripts
          defaultMode: 0755
  ingress:
    main:
      enabled: false
  service:
    main:
      nameOverride: qbittorrent
      enabled: true # necessary for probes, but probes aren't working with vpn addon currently
  env:
    # -- Set the container timezone
    TZ: UTC
    HOME: /config
    XDG_CONFIG_HOME: /config
    XDG_DATA_HOME: /config
    WAIT_FOR_VPN: "true"
  envFrom:
  - configMapRef:
      name: elfbot-qbittorrent
      optional: true    
  extraEnvVars:
  - name: PORT_FILE
    valueFrom:
      configMapKeyRef:
        name: qbittorrent-gluetun-config
        key: PORT_FILE
    optional: true
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # Remove the lockfile if it exists
        if [[ -f /config/qBittorrent/lockfile ]]; then
          rm /config/qBittorrent/lockfile
        fi

        mkdir -p /config/qBittorrent/torrent_files/complete
        mkdir -p /config/qBittorrent/torrent_files/incomplete

        # Enforce 1:1 seeding ratio, and then delete
        sed -i  "s/Session\\\GlobalMaxRatio=.*/Session\\\GlobalMaxRatio=1/" /config/qBittorrent/qBittorrent.conf

        # Permit TCP only
        sed -i  "s/Session\\\BTProtocol=.*/Session\\\BTProtocol=TCP/" /config/qBittorrent/qBittorrent.conf

        # Disable CSRF protection so that Homer can show qBit stats
        sed -i  "s/WebUI\\\CSRFProtection=.*/WebUI\\\CSRFProtection=false/" /config/qBittorrent/qBittorrent.conf

        # Insist on tun0
        sed -i  "s/Session\\\Interface=.*/Session\\\Interface=tun0/" /config/qBittorrent/qBittorrent.conf
        sed -i  "s/Session\\\InterfaceName=.*/Session\\\InterfaceName=tun0/" /config/qBittorrent/qBittorrent.conf

      volumeMounts:
      - mountPath: /config
        name: config
      securityContext: *default_securitycontext
      resources: *default_resources
  resources:
    requests:
      cpu: 100m
      memory: 512Mi
    limits:
      cpu: 500m
      memory: 1200Mi # .2 GB for headroom
  addons:
    vpn: &qbittorrent_addons_vpn
      enabled: true
      type: gluetun
      gluetun:
        image:
          repository: docker.io/qmcgaw/gluetun
          tag: pr-1543 # See https://github.com/qdm12/gluetun/issues/1488
      securityContext:
        runAsUser: 0
        capabilities:
          add:
            - NET_ADMIN
            - SYS_MODULE
      envFrom:
      - configMapRef:
          name: qbittorrent-gluetun-config
      additionalVolumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /storage/elfstorage
        name: elfstorage
      config: # We have to set this to null so that we can override with our own config

      # The scripts that get run when the VPN connection opens/closes are defined here.
      # The default scripts will write a string to represent the current connection state to a file.
      # Our qBittorrent image has a feature that can wait for this file to contain the word 'connected' before actually starting the application.
      scripts:
        up: |-
          #!/bin/bash
          echo "connected" > /shared/vpnstatus

        down: |-
          #!/bin/bash
          echo "disconnected" > /shared/vpnstatus


# Custom service for pia
qbittorrentpia:
  <<: *qbittorrent
  env:
    PORT_FILE: /config/forwarded-port
    WAIT_FOR_VPN: "true"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-qbittorrent,qbittorrent-pia-config"
  addons:
    vpn:
      <<: *qbittorrent_addons_vpn
      gluetun:
        image:
          repository: thrnz/docker-wireguard-pia
          tag: latest
      envFrom:
      - configMapRef:
          name: qbittorrent-pia-config
  additionalContainers:
    # Use this to provied proxied access to arrs
    dante:
      image: ghcr.io/geek-cookbook/dante:v1.4.3
      env: *bootstrap_env
      securityContext: *default_securitycontext   
      volumeMounts:
      - mountPath: /tmp
        name: tmp

nzbget:
  enabled: false
  sso:
    enabled: true
  image:
    repository: ghcr.io/geek-cookbook/nzbget
    tag: 21.1@sha256:672dec2779dfa82d475d7c2adb4296e361e06bf2f972aa1dbe827a4229c18020
  priorityClassName: tenant-bulk
  podLabels:
    app.elfhosted.com/class: bulk
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    nodeTaintsPolicy: Honor
    labelSelector: 
      matchLabels: 
        app.elfhosted.com/class: bulk       
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-nzbget"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nzbget-ssd          
    tmp:
      enabled: true
      type: custom
      mountPath: /tmp
      volumeSpec:
        ephemeral:
          volumeClaimTemplate:
            spec:
              accessModes: [ "ReadWriteOnce" ]
              storageClassName: "topolvm-provisioner-thin"
              resources:
                requests:
                  storage: 1000Gi      
      #   persistentVolumeClaim:
      #     claimName: config-nzbget-ssd          
      # sizeLimit: 1000Gi
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-nzbget
          optional: true

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap

sabnzbd:
  enabled: false
  hostname: sabnzbd # required to prevent whitelisting requirement per https://sabnzbd.org/wiki/extra/hostname-check.html
  podLabels:
    app.elfhosted.com/class: bulk  
  sso:
    enabled: true
  image:
    registry: ghcr.io
    repository: geek-cookbook/sabnzbd
    tag: 4.1.0@sha256:c2fec7d8609a138a12fed06756a12c0bb798d628592e24162bd9b19ae39b0f37
  priorityClassName: tenant-bulk
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    nodeTaintsPolicy: Honor
    labelSelector: 
      matchLabels: 
        app.elfhosted.com/class: bulk     
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-sabnzbd"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    runAsUser: 568
    runAsGroup: 568
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sabnzbd-ssd
    tmp:
      enabled: true
      type: custom
      mountPath: /tmp
      volumeSpec:
        ephemeral:
          volumeClaimTemplate:
            spec:
              accessModes: [ "ReadWriteOnce" ]
              storageClassName: "topolvm-provisioner-thin"
              resources:
                requests:
                  storage: 1000Gi      
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-sabnzbd
          optional: true
          

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/sh
      - -c
      - |
        set -x
        set -e

        # fix host_whitelist
        sed -i  's/goldilocks/{{ .Release.Name }}/g' /config/sabnzbd.ini
      volumeMounts:
      - mountPath: /config
        name: config
      env: *bootstrap_env
      securityContext: *default_securitycontext
      resources: *default_resources
  resources:
    requests:
      cpu: 10m
      memory: 512Mi
    limits:
      cpu: 1500m # if par threads is 1, this leaves 0.5cpu for downloading
      memory: 1500Mi
  env:
    HOST_WHITELIST_ENTRIES: "{{ .Release.Name }}.sabnzbd.elfhosted.com"
    SABNZBD_UID: 568
    SABNZBD_GID: 568

tautulli:
  enabled: false
  sso:
    enabled: true
  image:
    registry: ghcr.io
    repository: geek-cookbook/tautulli
    tag: 2.13.4@sha256:034ca5019ee840bc361a69d6fa6af5660c08eb9267f617c21940ac7a04366604
  priorityClassName: tenant-normal
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-tautulli"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-tautulli-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-tautulli
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 1
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap

radarr:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    registry: ghcr.io
    repository: geek-cookbook/radarr
    tag: 5.1.3.8246@sha256:ec2a8de9cc1295f7099b05f2d85b38beb80cc038406c91dafc32a43c97eb1cf1
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-radarr" # Reload the deployment every time the rclones change
  automountServiceAccountToken: false
  envFrom:
  - configMapRef:
      name: radarr-config
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-radarr-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-radarr
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/movies
        mkdir -p /storage/elfstorage/backup/auto/radarr

        # Set auth to external
        sed -i  "s|<AuthenticationMethod>None</AuthenticationMethod>|<AuthenticationMethod>External</AuthenticationMethod>|" /config/config.xml

      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      - mountPath: /config
        name: config
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 2
      memory: 1Gi

radarr4k:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    registry: ghcr.io
    repository: geek-cookbook/radarr
    tag: 5.1.3.8246@sha256:ec2a8de9cc1295f7099b05f2d85b38beb80cc038406c91dafc32a43c97eb1cf1
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-radarr4k" # Reload the deployment every time the rclones change
  automountServiceAccountToken: false
  envFrom:
  - configMapRef:
      name: radarr4k-config
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-radarr4k-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-radarr4k
          optional: true

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/movies4k
        mkdir -p /storage/elfstorage/backup/auto/radarr4k
        mkdir -p "/storage/elfstorage/downloads/completed/Movies 4K"

        # Set auth to external
        sed -i  "s|<AuthenticationMethod>None</AuthenticationMethod>|<AuthenticationMethod>External</AuthenticationMethod>|" /config/config.xml

      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      - mountPath: /config
        name: config
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 20m
      memory: 256Mi
    limits:
      cpu: 1
      memory: 1Gi

ombi:
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/ombi
    tag: 4.43.5@sha256:3d1e5dbdd073c38399a116f51b7341c59925598712c720681d28481c9479ffa5
  priorityClassName: tenant-normal
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-ombi"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    runAsNonRoot: true
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  sso:
    enabled: true
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-ombi-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-ombi
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes # need this for probes?
  initContainers:
    bootstrap: *bootstrap
  resources:
    requests:
      cpu: 3m
      memory: 150Mi
    limits:
      cpu: 2
      memory: 1Gi

bazarr:
  enabled: false
  sso:
    enabled: true
  image:
    registry: ghcr.io
    repository: geek-cookbook/bazarr
    tag: 1.4.0@sha256:2d3894f0e6c0c778f90c4fdc8950e85dc27bc81d445d86f935221b98c94c5212
  priorityClassName: tenant-normal
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-bazarr"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    runAsUser: 568
    runAsGroup: 568
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  envFrom:
  - configMapRef:
      name: bazarr-config     
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-bazarr-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-bazarr
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/backup/auto/bazarr
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 1
      memory: 1Gi

bazarr4k:
  enabled: false
  sso:
    enabled: true
  image:
    registry: ghcr.io
    repository: geek-cookbook/bazarr
    tag: 1.4.0@sha256:2d3894f0e6c0c778f90c4fdc8950e85dc27bc81d445d86f935221b98c94c5212
  priorityClassName: tenant-normal
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-bazarr4k"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    runAsUser: 568
    runAsGroup: 568
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  envFrom:
  - configMapRef:
      name: bazarr4k-config     
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-bazarr4k-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-bazarr4k
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/backup/auto/bazarr4k
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 1
      memory: 1Gi


autobrr:
  enabled: false
  sso:
    enabled: true
  image:
    registry: ghcr.io
    repository: geek-cookbook/autobrr
    tag: 1.34.1@sha256:cb1e9a9bb7606145c91af7dcc01dc53877722b2ae81f7dccb027d60cae028eee
  priorityClassName: tenant-normal
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-autobrr"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true # doesn't seem to work with upgrades
    allowPrivilegeEscalation: false
    runAsUser: 568
    runAsGroup: 568
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-autobrr-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-autobrr
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 3
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap
  # additionalContainers:
  #   regbrr:
  #     image: ghcr.io/geek-cookbook/docker-autobrr-helper:sha-0dcb44a
  #     imagePullPolicy: IfNotPresent
  #     command:
  #     - /bin/sh
  #     - -c
  #     - |
  #       while true
  #       do
  #         /regbrr.sh
  #         sleep 1d
  #       done
  #     securityContext:
  #       seccompProfile:
  #         type: RuntimeDefault
  #       readOnlyRootFilesystem: true # doesn't seem to work with upgrades
  #       allowPrivilegeEscalation: false
  #       runAsUser: 568
  #       runAsGroup: 568
  #     volumeMounts:
  #     - mountPath: /config
  #       name: config
  #       subPath: autobrr

filebrowser:
  enabled: true
  podLabels:
    app.elfhosted.com/name: filebrowser
  image:
    repository: ghcr.io/geek-cookbook/filebrowser
    tag: 2.23.0@sha256:1db0f0114a169ea2a877d75c47903a6d01534340421948845d5e298c7ac7ceb4
  env:
    FB_DATABASE: /tmp/filebrowser.db
    FB_CONFIG: /etc/filebrowser/.filebrowser.json # this would work implicitly anyway, but this way it's clear what's happening
    FB_ADDRESS: 0.0.0.0
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    runAsUser: 568
    runAsGroup: 568
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,filebrowser-elfbot-script,elfbot-filebrowser" # Reload the deployment every time the rclones change
    strategy: RollingUpdate
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists    
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    nodeTaintsPolicy: Honor
    labelSelector: 
      matchLabels: 
        app.elfhosted.com/name: filebrowser    
  # We will use this to alter configmaps to trigger pod restarts
  serviceAccount:
    create: true
    name: filebrowser
  automountServiceAccountToken: true
  persistence:
    <<: *appmounts
    dummy-storage: # so auto-provisioning doesn't break
      enabled: true
      type: emptyDir
      sizeLimit: 1Gi
    elfbot:
      enabled: true
      type: emptyDir
      sizeLimit: 1Gi
      mountPath: /elfbot
    elfbot-script:
      enabled: "true"
      mountPath: "/usr/local/bin/elfbot"
      subPath: "elfbot"
      type: "custom"
      volumeSpec:
        configMap:
          name: filebrowser-elfbot-script
          defaultMode: 0755
    elfbot-script-ucfirst:
      enabled: "true"
      mountPath: "/usr/local/bin/Elfbot" # make it easier for mobile users
      subPath: "elfbot"
      type: "custom"
      volumeSpec:
        configMap:
          name: filebrowser-elfbot-script
          defaultMode: 0755


    # We need one of these per-app. The global section will override the false enablement
    autobrr:
      enabled: false
      type: custom
      mountPath: /storage/config/autobrr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-autobrr-ssd
    autoscan:
      enabled: false
      type: custom
      mountPath: /storage/config/autoscan/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-autoscan-ssd            
    audiobookshelf:
      enabled: false
      type: custom
      mountPath: /storage/config/audiobookshelf/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-audiobookshelf-ssd
    bazarr:
      enabled: false
      type: custom
      mountPath: /storage/config/bazarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-bazarr-ssd
    bazarr4k:
      enabled: false
      type: custom
      mountPath: /storage/config/bazarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-bazarr4k-ssd
    calibreweb:
      enabled: false
      type: custom
      mountPath: /storage/config/calibreweb/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-calibreweb-ssd
    calibre:
      enabled: false
      type: custom
      mountPath: /storage/config/calibre/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-calibre-ssd
    delugepia:
      enabled: false
      type: custom
      mountPath: /storage/config/deluge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-deluge-ssd
    delugegluetun:
      enabled: false
      type: custom
      mountPath: /storage/config/deluge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-deluge-ssd
    emby:
      enabled: false
      type: custom
      mountPath: /storage/config/emby/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-emby-ssd
    filebot:
      enabled: false
      type: custom
      mountPath: /storage/config/filebot/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-filebot-ssd
    gotify:
      enabled: false
      type: custom
      mountPath: /storage/config/gotify/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-gotify-ssd           
    homepage:
      enabled: false
      type: custom
      mountPath: /storage/config/homepage/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-homepage-ssd
    jellyseerr:
      enabled: false
      type: custom
      mountPath: /storage/config/jellyseerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jellyseerr-ssd
    pyload:
      enabled: false
      type: custom
      mountPath: /storage/config/pyload/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-pyload-ssd
    jdownloader:
      enabled: false
      type: custom
      mountPath: /storage/config/jdownloader/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jdownloader-ssd
    jellyfin:
      enabled: false
      type: custom
      mountPath: /storage/config/jellyfin/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jellyfin-ssd
    plexmetamanager:
      enabled: false
      type: custom
      mountPath: /storage/config/plexmetamanager/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plexmetamanager-ssd
    plexpia:
      enabled: false
      type: custom
      mountPath: /storage/config/plex/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    plexgluetun:
      enabled: false
      type: custom
      mountPath: /storage/config/plex/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    joplinserver:
      enabled: false
      type: custom
      mountPath: /storage/config/joplin-server/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-joplinserver
    jfa:
      enabled: false
      type: custom
      mountPath: /storage/config/jfa/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jfa-ssd
    kavita:
      enabled: false
      type: custom
      mountPath: /storage/config/kavita/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-kavita-ssd
    komga:
      enabled: false
      type: custom
      mountPath: /storage/config/komga/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-komga-ssd
    lazylibrarian:
      enabled: false
      type: custom
      mountPath: /storage/config/lazylibrarian/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-lazylibrarian-ssd
    lidarr:
      enabled: false
      type: custom
      mountPath: /storage/config/lidarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-lidarr-ssd
    mattermost:
      enabled: false
      type: custom
      mountPath: /storage/config/mattermost/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-mattermost-ssd
    mylar:
      enabled: false
      type: custom
      mountPath: /storage/config/mylar/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-mylar-ssd
    navidrome:
      enabled: false
      type: custom
      mountPath: /storage/config/navidrome/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-navidrome-ssd
    nextpvr:
      enabled: false
      type: custom
      mountPath: /storage/config/nextpvr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nextpvr-ssd
    notifiarr:
      enabled: false
      type: custom
      mountPath: /storage/config/notifiarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-notifiarr-ssd
    nzbget:
      enabled: false
      type: custom
      mountPath: /storage/config/nzbget/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nzbget-ssd
    nzbhydra:
      enabled: false
      type: custom
      mountPath: /storage/config/nzbhydra/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nzbhydra-ssd
    ombi:
      enabled: false
      type: custom
      mountPath: /storage/config/ombi/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-ombi-ssd
    openbooks:
      enabled: false
      type: custom
      mountPath: /storage/config/openbooks/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-openbooks-ssd
    overseerr:
      enabled: false
      type: custom
      mountPath: /storage/config/overseerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-overseerr-ssd
    privatebin:
      enabled: false
      type: custom
      mountPath: /storage/config/privatebin/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-privatebin-ssd
    prowlarr:
      enabled: false
      type: custom
      mountPath: /storage/config/prowlarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-prowlarr-ssd
    qbittorrentpia:
      enabled: false
      type: custom
      mountPath: /storage/config/qbittorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-qbittorrent-ssd
    qbittorrentgluetun:
      enabled: false
      type: custom
      mountPath: /storage/config/qbittorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-qbittorrent-ssd
    radarr:
      enabled: false
      type: custom
      mountPath: /storage/config/radarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-radarr-ssd
    radarr4k:
      enabled: false
      type: custom
      mountPath: /storage/config/radarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-radarr4k-ssd
    rapidleech:
      enabled: false
      type: custom
      mountPath: /storage/config/rapidleech/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rapidleech-ssd
    rclonebrowser:
      enabled: true # this is always on
      type: custom
      mountPath: /storage/config/rclonebrowser/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rclonebrowser-ssd
    readarr:
      enabled: false
      type: custom
      mountPath: /storage/config/readarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-readarr-ssd
    readarraudio:
      enabled: false
      type: custom
      mountPath: /storage/config/readarraudio/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-readarraudio-ssd
    resiliosync:
      enabled: false
      type: custom
      mountPath: /storage/config/resiliosync/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-resiliosync-ssd
    rpdb:
      enabled: false
      type: custom
      mountPath: /storage/config/rpdb/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rpdb-ssd
    rutorrentpia:
      enabled: false
      type: custom
      mountPath: /storage/config/rutorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rutorrent-ssd
    rutorrentgluetun:
      enabled: false
      type: custom
      mountPath: /storage/config/rutorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rutorrent-ssd
    sabnzbd:
      enabled: false
      type: custom
      mountPath: /storage/config/sabnzbd/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sabnzbd-ssd
    seafile:
      enabled: false
      type: custom
      mountPath: /storage/config/seafile/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-seafile
    shoko:
      enabled: false
      type: custom
      mountPath: /storage/config/shoko/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-shoko-ssd
    sonarr:
      enabled: false
      type: custom
      mountPath: /storage/config/sonarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sonarr-ssd
    sonarr4k:
      enabled: false
      type: custom
      mountPath: /storage/config/sonarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sonarr4k-ssd
    syncthing:
      enabled: false
      type: custom
      mountPath: /storage/config/syncthing/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-syncthing
    tautulli:
      enabled: false
      type: custom
      mountPath: /storage/config/tautulli/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-tautulli-ssd
    tdarr:
      enabled: false
      type: custom
      mountPath: /storage/config/tdarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-tdarr-ssd
    thelounge:
      enabled: false
      type: custom
      mountPath: /storage/config/thelounge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-thelounge-ssd
    unpackerr:
      enabled: false
      type: custom
      mountPath: /storage/config/unpackerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-unpackerr-ssd          
    uptimekuma:
      enabled: false
      type: custom
      mountPath: /storage/config/uptimekuma/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-uptimekuma-ssd          
    vaultwarden:
      enabled: false
      type: custom
      mountPath: /storage/config/vaultwarden/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-vaultwarden-ssd
    xteve:
      enabled: false
      type: custom
      mountPath: /storage/config/xteve/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-xteve-ssd
    youtubedl:
      enabled: false
      type: custom
      mountPath: /storage/config/youtubedl/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-youtubedl-ssd
    rdtclient:
      enabled: false
      type: custom
      mountPath: /storage/config/rdtclient/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rdtclient-ssd
  service:
    main:
      enabled: true # necessary for probes
      ports:
        http:
          port: 8080 # this allows us to run as non-root

  ingress:
    main:
      enabled: false
  initContainers:
    setup:
      image: ghcr.io/geek-cookbook/filebrowser:2.26.0@sha256:762d5c3407b872fd498a7f0cb694adbcfe74e33f13b3137092b29bdff49d09aa
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # Delete tmp db if necessary
        if [ -f /tmp/filebrowser.db ]
        then
          rm /tmp/filebrowser.db
        fi

        /filebrowser config init \
          --disable-preview-resize \
          --disable-thumbnails \
          --disable-type-detection-by-header \
          --branding.name="{{ .Release.Name }}, by ElfHosted 🧝 " \
          --branding.files=/branding \
          --branding.disableExternal \
          --auth.method=noauth \
          --lockPassword \
          --database /tmp/filebrowser.db \
          --root /storage \
          --cache-dir /tmp

        # allow zip, unzip, rar, unrar, ls, pwd, cd, mv
        /filebrowser config set --database /tmp/filebrowser.db --commands zip,unzip,rar,unrar,ls,pwd,cd,mv,cp,ln,find,echo,grep,cat,touch,tar,gzip,rm,tree,du,mlocate,updatedb,locate,elfbot,Elfbot
        # /filebrowser config set --database /tmp/filebrowser.db --shell 'vstat -c'

        # now tell filebrowser about the user (who gets authenticated via the proxy)
        /filebrowser users add 1 bogus --database /tmp/filebrowser.db


      volumeMounts:
      - mountPath: /tmp
        name: tmp
      - mountPath: /storage
        name: dummy-storage
      resources: *default_resources
      securityContext: *default_securitycontext
  additionalContainers:
    # this container exists to watch for restarts requested by elfbot, and to use create configmaps to trigger restarts using reloader
    elfbot:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /usr/bin/dumb-init
      - /bin/bash
      - -c
      - |
        set -e
        set -x

        inotifywait -m -e create --format "%f" /elfbot \
          | while read APP
            do
              # put the contents of the file into the configmap which will trigger the restart
              echo command received for ${APP} : [$(cat /elfbot/$APP)]
              # create the configmap if it doesn't exist, since reloader only looks at _changes_ to configmaps
              if ! $(kubectl get configmap -n {{ .Release.Namespace }} elfbot-${APP} 2>&1 >/dev/null); then
                  kubectl create configmap -n {{ .Release.Namespace }} elfbot-${APP} --from-literal=elfbot_last_action=$(date +%s)
                  sleep 10s
              fi

              # If we were passed a key=value string in /etc/elfbot, then split it
              if (cat /elfbot/$APP | grep -q =); then
                KEY=$(cat /elfbot/$APP | cut -f1 -d=)
                VALUE=$(cat /elfbot/$APP | cut -f2 -d=)
              # If not, then it was just a simple command, like "backup"
              else
                KEY=$(cat /elfbot/$APP)
                VALUE=$(date +%s)
              fi

              # patch the configmap with the latest key/value
              kubectl patch configmap -n {{ .Release.Namespace }} elfbot-${APP} -p "{\"data\":{\"${KEY}\":\"${VALUE}\"}}"

              # kubectl create configmap -n {{ .Release.Namespace }} \
              # elfbot-${APP} --from-literal=$(cat /elfbot/$APP)=$(date +%s) --from-literal=elfbot_last_action=$(date +%s) -o yaml --dry-run=client \
              # | kubectl apply -f -
              rm /elfbot/$APP
            done
      volumeMounts:
      - mountPath: /elfbot
        name: elfbot
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 10m
      memory: 10Mi
    limits:
      cpu: 200m
      memory: 514Mi

  # # not used currently
  # config: |
  #   {
  #     "port": 8080,
  #     "baseURL": "",
  #     "address": "0.0.0.0",
  #     "log": "stdout",
  #     "database": "/tmp/filebrowser.db",
  #     "root": "/elfhosted",
  #     "enableExec": "true"
  #   }



uptimekuma:
  enabled: false
  sso:
    enabled: true
  image:
    repository: ghcr.io/geek-cookbook/uptime-kuma
    tag: 1.23.9@sha256:7aafb5f98fe22049006730e0402bae2cc8b8fab3b04eb82def309a26f7ab2626
  priorityClassName: tenant-normal
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-uptimekuma"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /app/data/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-uptimekuma-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-uptimekuba
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
  resources:
    requests:
      cpu: 10m
      memory: 96Mi
    limits:
      cpu: 100m
      memory: 200Mi

privatebin:
  enabled: false
  sso:
    enabled: false
  image:
    repository: privatebin/fs
    tag: 1.6.2
  priorityClassName: 
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-privatebin"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # crashes privatebin, TBD to determine why, and whether an emptydir /tmpfs might help
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /srv/data
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-privatebin-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-privatebin
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 100m
      memory: 128Mi
  config:
    main:
      discussion: false
      opendiscussion: false
      password: true
      fileupload: true
      burnafterreadingselected: false
      defaultformatter: "plaintext"
      syntaxhighlightingtheme: "sons-of-obsidian"
      sizelimit: 1048576
      template: "bootstrap-dark"
      info: "Hosted with ❤️ by ElfHosted 🧝"
      languageselection: true
      languagedefault: "en"
      # urlshortener: "https://shortener.example.com/api?link="
      qrcode: false
      icon: "none"
      zerobincompatibility: false
      # httpwarning: true
      compression: "zlib"
    expire:
      default: "1week"
    expire_options:
      5min: 300
      10min: 600
      1hour: 3600
      1day: 86400
      1week: 604800
    formatter_options:
      plaintext: "Plain Text"
      syntaxhighlighting: "Source Code"
      markdown: "Markdown"
    traffic:
      limit: 10
      # exemptedIp: "1.2.3.4,10.10.10/24"
  initContainers:
    bootstrap: *bootstrap

nzbhydra:
  enabled: false
  sso:
    enabled: true
  image:
    registry: ghcr.io
    repository: geek-cookbook/nzbhydra2
    tag: 5.3.5@sha256:7e9a121eba698f7f4cee50da3ebcecaf58635e4ba8e4f170cba11c4a2f561fd5
  priorityClassName: 
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-nzbhydra"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    runAsUser: 568
    runAsGroup: 568
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  probes:
    liveness:
      enabled: false
    startup:
      enabled: false
    readiness:
      enabled: false
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nzbhydra-ssd          
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-nzbhydra
          optional: true
    tmp: *tmp
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for custom probes
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 1
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap

calibreweb:
  enabled: false
  sso:
    enabled: true
  priorityClassName: 
  image:
    repository: ghcr.io/geek-cookbook/calibre-web
    tag: 0.6.21@sha256:f020940a67792fd31c73c163b360a40d47be1bd4d332fc6bd6eb709e68ad0c06
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-calibreweb"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    # readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  automountServiceAccountToken: false
  environment:
    CALIBRE_DBPATH: /config
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-calibreweb-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-calibreweb
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 10
      memory: 1Gi

pyload:
  enabled: false
  sso:
    enabled: true
  priorityClassName: 
  image:
    repository: ghcr.io/geek-cookbook/pyload-ng
    tag: 0.5.0b3.dev71@sha256:17b0414059c2aad0ae0318244a4f024f3e54851430ad6d44bedba260466c78d2
  env:
    PUID: 568
    PGID: 568
    # S6_READ_ONLY_ROOT: 1
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-pyload"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # again, s6
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists

  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    run: # used for s6-init with non-root
      enabled: true
      type: emptyDir
      mountPath: /run
      sizeLimit: 1Gi
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-pyload
          optional: true
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-pyload-ssd
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 40Mi
    limits:
      cpu: 1
      memory: 1Gi

lazylibrarian:
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/lazylibrarian
    tag: rolling@sha256:dfb26b96f341f3728cd8f7f395cc1e7de9d13d2c6d9667394e810bf87ea39149
  enabled: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-lazylibrarian"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    runAsUser: 568
    runAsGroup: 568
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-lazylibrarian-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-lazylibrarian
          optional: true

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
  resources:
    requests:
      cpu: 10m
      memory: 96Mi
    limits:
      cpu: 1
      memory: 1Gi

mylar:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    registry: ghcr.io
    repository: geek-cookbook/mylar3
    tag: 0.7.6@sha256:5bb74fb44c92658601991a0dadc20d46245706f1a1d57e25bc38a0d43755ed49
  env:
    PUID: 568
    PGID: 568
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    # readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-mylar" # Reload the deployment every time the rclones change
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-mylar-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-mylar
          optional: true

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/comics
        mkdir -p /storage/elfstorage/backup/auto/mylar
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 1
      memory: 1Gi

komga:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/komga
    tag: 1.9.0@sha256:4754253b704d12e9b9474561d77fc5beff3ebb67164fd4aad94327ddbef8d6b1
  env:
    KOMGA_CONFIGDIR: /config
    KOMGA_REMEMBERME_KEY: yesplease
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-komga" # Reload the deployment every time the rclones change
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-komga-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-komga
          optional: true

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
  resources:
    requests:
      cpu: 10m
      memory: 512Mi
    limits:
      cpu: 1
      memory: 1Gi

kavita:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/kavita
    tag: 0.7.11@sha256:efdbf362e3a8eda6bbed89f633c26f9df4af55b5852d71f5e50d3a620f54f2ae
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-kavita" # Reload the deployment every time the rclones change
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /kavita/config
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-kavita-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-kavita
          optional: true
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 96Mi
    limits:
      cpu: 2
      memory: 1Gi

calibre:
  enabled: false
  sso:
    enabled: true
  runtimeClassName: kata
  image:
    repository: quay.io/linuxserver.io/calibre
    tag: 7.2.0@sha256:c5af242b4c6549a3c151f73c9b824f10779f65e7a09cab237873e901804a54b4
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # doesn't work with s6
    allowPrivilegeEscalation: false # do we need this too?
    # runAsUser: 568
    # runAsGroup: 568
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-calibre"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-calibre-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-calibre
          optional: true
    run: # used for s6-init with non-root
      enabled: true
      type: emptyDir
      mountPath: /run
      sizeLimit: 1Gi
  env:
    PUID: 568
    PGID: 568
    TITLE: Calibre | ElfHosted
    START_DOCKER: false
    # CLI_ARGS: "--with-library=/storage/elfstorage/books"
  ingress:
    main:
      enabled: false
  service:
    main:
      ports:
        http:
          port: 8080
  resources:
    requests:
      cpu: 10m
      memory: 1Gi
    limits:
      cpu: 1
      memory: 4Gi
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/sh
      - -c
      - |
        set -x
        set -e
        if [ ! -f /storage/elfstorage/books/metadata.db ]
        then
          echo "Copying sample Calibre DB files to /storage/elfstorage/books/..."
          mkdir -p /storage/elfstorage/books
          cp /config/metadata* /storage/elfstorage/books/
        fi
      volumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext

sonarr:
  service:
    main:
      enabled: false
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    registry: ghcr.io
    repository: geek-cookbook/sonarr-develop
    tag: 4.0.0.737@sha256:6219f456ce42ad9098293787d3215310935d03526f6e58f232b32e88cba1b531
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-sonarr" # Reload the deployment every time the rclones change
  automountServiceAccountToken: false
  envFrom:
  - configMapRef:
      name: sonarr-config     
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sonarr-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-sonarr
          optional: true

  ingress:
    main:
      enabled: false
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/series
        mkdir -p /storage/elfstorage/backup/auto/sonarr
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 10m
      memory: 192Mi
    limits:
      cpu: 2
      memory: 1Gi


sonarr4k:
  service:
    main:
      enabled: false
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    registry: ghcr.io
    repository: geek-cookbook/sonarr-develop
    tag: 4.0.0.737@sha256:6219f456ce42ad9098293787d3215310935d03526f6e58f232b32e88cba1b531
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-sonarr4k" # Reload the deployment every time the rclones change
  automountServiceAccountToken: false
  envFrom:
  - configMapRef:
      name: sonarr4k-config     
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sonarr4k-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-sonarr4k
          optional: true
  ingress:
    main:
      enabled: false
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/series
        mkdir -p /storage/elfstorage/backup/auto/sonarr4k
        mkdir -p "/storage/elfstorage/downloads/completed/Series 4K"
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 1
      memory: 1Gi

resiliosync:
  service:
    main:
      enabled: false
  command:
  - rslsync
  - --config
  - /sync.conf
  - --nodaemon
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-bulk
  image:
    repository: ghcr.io/geek-cookbook/resilio-sync
    tag: 2.7.3.1381-1@sha256:e73ca73c5b726362aceb0be808e409d346eb42072ab57db8d90fd0d93003d265
  env:
    PUID: 568
    GUID: 568
    S6_READ_ONLY_ROOT: 1
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # another s6 containeir!
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-resiliosync"
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists      
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-resiliosync-ssd
    setup-config:
      enabled: "true"
      mountPath: "/sync.conf"
      subPath: "sync.conf"
      type: "custom"
      volumeSpec:
        configMap:
          name: resiliosync-config
    run: # used for s6-init with non-root
      enabled: true
      type: emptyDir
      mountPath: /run
      sizeLimit: 1Gi
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-resiliosync
          optional: true

  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 1
      memory: 1Gi

prowlarr:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    registry: ghcr.io
    repository: geek-cookbook/prowlarr-develop
    tag: 1.11.2.4160@sha256:f8afe265db8142a4a956ec2f312df7e2c40ffbc015edcb0d8cbc28ee0b2c0a3c
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    # readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-prowlarr"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-prowlarr-ssd
    run: # used for s6-init with non-root
      enabled: true
      type: emptyDir
      mountPath: /run
      sizeLimit: 1Gi
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-prowlarr
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/sh
      - -c
      - |
        set -x
        set -e
        # Set auth to external
        sed -i  "s|<AuthenticationMethod>None</AuthenticationMethod>|<AuthenticationMethod>External</AuthenticationMethod>|" /config/config.xml
        mkdir -p /storage/elfstorage/backup/auto/prowlarr
      volumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 60m
      memory: 128Mi
    limits:
      cpu: 2
      memory: 1Gi
  env:
    S6_READ_ONLY_ROOT: 1

lidarr:
  enabled: false
  sso:
    enabled: true
  image:
    registry: ghcr.io
    repository: geek-cookbook/lidarr-develop
    tag: 2.0.7.3849@sha256:8ed290727b70cc7972e949748556267038600e26d79a0b1b414356b0b4126ac7
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    # readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-lidarr" # Reload the deployment every time the rclones change
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-lidarr-ssd
    s6:
      enabled: true
      type: emptyDir
      mountPath: /var/run/s6
      sizeLimit: 1Gi
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-lidarr
          optional: true

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/music
        mkdir -p /storage/elfstorage/backup/auto/lidarr
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 20m
      memory: 128Mi
    limits:
      cpu: 2
      memory: 1Gi

navidrome:
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/navidrome
    tag: 0.49.3@sha256:1e37fb56a053b9e61313061c38633d552a13a3bee5f6d9a1fc4a9f610a041008
  sso:
    enabled: true
  priorityClassName: tenant-streaming
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-navidrome"
  automountServiceAccountToken: false
  env:
    ND_MUSICFOLDER: /storage/elfstorage/music
    ND_DATAFOLDER: /config
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-navidrome-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-navidrome
          optional: true
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/music
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 16Mi
    limits:
      cpu: 2
      memory: 1Gi

readarr:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    registry: ghcr.io
    repository: geek-cookbook/readarr-nightly
    tag: 0.3.12.2327@sha256:076d118630594502971ef397f138da3d8858c95bf59dfcd6ae4ae444f57925a0
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-readarr" # Reload the deployment every time the rclones change
  automountServiceAccountToken: false
  envFrom:
  - configMapRef:
      name: readarr-config  
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-readarr-ssd
    tmp-readarr-backup:
      enabled: true
      type: emptyDir
      mountPath: /tmp/readarr_backup
      sizeLimit: 32Mi
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-readarr
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/books
        mkdir -p /storage/elfstorage/backup/auto/readarr
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 20m
      memory: 128Mi
    limits:
      cpu: 2
      memory: 1Gi

readarraudio:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    registry: ghcr.io
    repository: geek-cookbook/readarr-nightly
    tag: 0.3.12.2327@sha256:076d118630594502971ef397f138da3d8858c95bf59dfcd6ae4ae444f57925a0
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  envFrom:
  - configMapRef:
      name: readarraudio-config   
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-readarraudio" # Reload the deployment every time the rclones change
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-readarraudio-ssd
    tmp-readarr-backup:
      enabled: true
      type: emptyDir
      mountPath: /tmp/readarr_backup
      sizeLimit: 32Mi
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-readarraudio
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /storage/elfstorage/audiobooks
        mkdir -p /storage/elfstorage/backup/auto/readarraudio
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext
  resources:
    requests:
      cpu: 20m
      memory: 128Mi
    limits:
      cpu: 2
      memory: 1Gi

plex: &plex
  enabled: false
  priorityClassName: tenant-streaming
  podLabels:
    app.elfhosted.com/name: plex
  securityContext:
    runAsUser: 568
    runAsGroup: 568
    privileged: true
  podSecurityContext:
    fsGroup: 568
    fsGroupChangePolicy: "Always"
    seccompProfile:
      type: RuntimeDefault
    supplementalGroups:
    - 109
  automountServiceAccountToken: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-plex" # Reload the deployment every time the rclones change
  image:
    registry: ghcr.io
    repository: geek-cookbook/plex
    tag: 1.32.7.7621-871adbd44
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    transcode:
      enabled: true
      type: emptyDir
      mountPath: /transcode
      sizeLimit: 50Gi # Don't allow > 50GB in transcoding files
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-plex
          optional: true
    render-device:
      enabled: "true"
      type: hostPath
      hostPath: "/dev/dri/renderD128"
      mountPath: "/dev/dri/renderD128"

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  env:
    # PLEX_PREFERENCE_1: "FriendlyName=ElfHosted | {{ .Release.Name }}"
    PLEX_PREFERENCE_2: "FSEventLibraryPartialScanEnabled=1"
    PLEX_PREFERENCE_3: "FSEventLibraryUpdatesEnabled=1"
    PLEX_PREFERENCE_4: "ScannerLowPriority=1"
    PLEX_PREFERENCE_5: "ScheduledLibraryUpdatesEnabled=0"
    PLEX_PREFERENCE_6: "TranscodeCountLimit=3"
    PLEX_PREFERENCE_7: "TranscoderQuality=1"
    PLEX_PREFERENCE_8: "BackgroundTranscodeLowPriority=1"
    PLEX_PREFERENCE_9: "LongRunningJobThreads=1"
    PLEX_PREFERENCE_10: "TranscoderH264BackgroundPreset=ultrafast"
    PLEX_PREFERENCE_11: "RelayEnabled=0"
    PLEX_PREFERENCE_12: "TranscoderTempDirectory=/transcode"
    PLEX_PREFERENCE_13: "MinutesAllowedPaused=30"
    PLEX_PREFERENCE_14: "GenerateIntroMarkerBehavior=scheduled"
    PLEX_PREFERENCE_15: "ButlerStartHour=5"
    PLEX_PREFERENCE_16: "ButlerEndHour=13"
    ADVERTISE_IP: "https://{{ .Release.Name }}-plex.elfhosted.com:443"
  resources:
    requests:
      cpu: "10m"
      memory: 512Mi
    limits:
      cpu: "2"
      memory: 2048Mi
  initContainers:
    bootstrap: *bootstrap

plexgluetun:
  <<: *plex
  enabled: false
  podLabels:
    app.elfhosted.com/name: plex
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-plex,plex-gluetun-config"
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    shared:
      enabled: true
      mountPath: /shared
      type: emptyDir
      volumeSpec:
        medium: Memory
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-plex
          optional: true
    transcode:
      enabled: true
      type: emptyDir
      mountPath: /transcode
      sizeLimit: 50Gi # Don't allow > 50GB in transcoding files
  service:
    main:
      nameOverride: plex
      enabled: true # necessary for probes, but probes aren't working with vpn addon currently
  addons:
    vpn: &plex_addons_vpn
      enabled: true
      type: gluetun
      gluetun:
        image:
          repository: docker.io/qmcgaw/gluetun
          tag: pr-1543 # See https://github.com/qdm12/gluetun/issues/1488
      securityContext:
        runAsUser: 0
        capabilities:
          add:
            - NET_ADMIN
            - SYS_MODULE
      envFrom:
      - configMapRef:
          name: plex-gluetun-config
      additionalVolumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /storage/elfstorage
        name: elfstorage
      config: # We have to set this to null so that we can override with our own config

      # The scripts that get run when the VPN connection opens/closes are defined here.
      # The default scripts will write a string to represent the current connection state to a file.
      # Our qBittorrent image has a feature that can wait for this file to contain the word 'connected' before actually starting the application.
      scripts:
        up: |-
          #!/bin/bash
          echo "connected" > /shared/vpnstatus

        down: |-
          #!/bin/bash
          echo "disconnected" > /shared/vpnstatus

plexpia:
  <<: *plex
  enabled: false
  podLabels:
    app.elfhosted.com/name: plex
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-plex,plex-pia-config"
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    shared:
      enabled: true
      mountPath: /shared
      type: emptyDir
      volumeSpec:
        medium: Memory
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-plex
          optional: true
    transcode:
      enabled: true
      type: emptyDir
      mountPath: /transcode
      sizeLimit: 50Gi # Don't allow > 50GB in transcoding files
  addons:
    vpn:
      <<: *plex_addons_vpn
      gluetun:
        image:
          repository: thrnz/docker-wireguard-pia
          tag: latest
      envFrom:
      - configMapRef:
          name: plex-pia-config

jellyfin:
  hostname: elfhosted
  image:
    repository: ghcr.io/geek-cookbook/jellyfin
    tag: 10.8.13@sha256:e49a5e445a473f8263d9bfbc5c26aaa32d5be0cde7866e5c88165a364098e58f
  enabled: false
  priorityClassName: tenant-streaming
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
    privileged: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
    runAsUser: 568
    runAsGroup: 568
    supplementalGroups:
    - 109
  automountServiceAccountToken: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-jellyfin" # Reload the deployment every time the rclones change
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jellyfin-ssd
    transcode:
      enabled: true
      type: emptyDir
      mountPath: /config/transcodes
      sizeLimit: 50Gi # Don't allow > 10GB in transcoding files
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-jellyfin
          optional: true
    render-device:
      enabled: "true"
      type: hostPath
      hostPath: "/dev/dri/renderD128"
      mountPath: "/dev/dri/renderD128"
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 512Mi
    limits:
      cpu: 2
      memory: 2Gi
  additionalContainers:
    jellyfixer:
      image: quay.io/xsteadfastx/jellyfixer:latest
      env:
        JELLYFIXER_INTERNAL_URL: http://jellyfin:8096
        JELLYFIXER_EXTERNAL_URL: https://{{ .Release.Name }}-jellyfin.elfhosted.com

emby:
  hostname: elfhosted
  image:
    registry: ghcr.io
    repository: geek-cookbook/emby
    tag: 4.7.14.0@sha256:ccdad65c7c631f60f9b1859e748d075b5923249b0f6b1f2c6058ad8942417fcc
  enabled: false
  priorityClassName: tenant-streaming
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem:
    privileged: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
    supplementalGroups:
    - 109
  automountServiceAccountToken: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-emby" # Reload the deployment every time the rclones change
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-emby-ssd
    transcode-temp:
      enabled: true
      type: emptyDir
      mountPath: /config/transcoding-temp
      sizeLimit: 50Gi # Don't allow > 10GB in transcoding files
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-emby
          optional: true
    render-device:
      enabled: "true"
      type: hostPath
      hostPath: "/dev/dri/renderD128"
      mountPath: "/dev/dri/renderD128"

  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: "10m"
      memory: 512Mi
    limits:
      cpu: 1
      memory: 2048Mi

homer:
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
    runAsNonRoot: false
  podSecurityContext:
    runAsNonRoot: false
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "Always"
  automountServiceAccountToken: false
  image:
    repository: ghcr.io/geek-cookbook/tooling
    tag: focal-20230605@sha256:dac41eb12f3762284fa6963ee5821688fdd40efdad710a2d9f8b3579fbc8f1cc
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  persistence:
    <<: *appmounts
    config-yml:
      enabled: "true"
      subPath: "config.yml"
      type: "custom"
      volumeSpec:
        configMap:
          name: homer-config
    tools-yml:
      enabled: "true"
      subPath: "tools.yml"
      type: "custom"
      volumeSpec:
        configMap:
          name: homer-config
    disk-usage:
      enabled: "true"
      mountPath: "/usr/local/bin/disk_usage.sh"
      subPath: "disk_usage.sh"
      type: "custom"
      volumeSpec:
        configMap:
          name: homer-config
    # We need one of these per-app. The global section will override the false enablement
    autobrr:
      enabled: false
      type: custom
      mountPath: /config/autobrr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-autobrr-ssd
    autoscan:
      enabled: false
      type: custom
      mountPath: /config/autoscan/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-autoscan-ssd          
    audiobookshelf:
      enabled: false
      type: custom
      mountPath: /config/audiobookshelf/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-audiobookshelf-ssd
    bazarr:
      enabled: false
      type: custom
      mountPath: /config/bazarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-bazarr-ssd
    bazarr4k:
      enabled: false
      type: custom
      mountPath: /config/bazarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-bazarr4k-ssd
    calibreweb:
      enabled: false
      type: custom
      mountPath: /config/calibreweb/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-calibreweb-ssd
    calibre:
      enabled: false
      type: custom
      mountPath: /config/calibre/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-calibre-ssd
    delugepia:
      enabled: false
      type: custom
      mountPath: /config/deluge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-deluge-ssd
    delugegluetun:
      enabled: false
      type: custom
      mountPath: /config/deluge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-deluge-ssd
    emby:
      enabled: false
      type: custom
      mountPath: /config/emby/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-emby-ssd
    filebot:
      enabled: false
      type: custom
      mountPath: /config/filebot/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-filebot-ssd
    gotify:
      enabled: false
      type: custom
      mountPath: /config/gotify/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-gotify-ssd           
    homepage:
      enabled: false
      type: custom
      mountPath: /config/homepage/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-homepage-ssd
    jellyseerr:
      enabled: false
      type: custom
      mountPath: /config/jellyseerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jellyseerr-ssd
    pyload:
      enabled: false
      type: custom
      mountPath: /config/pyload/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-pyload-ssd
    jdownloader:
      enabled: false
      type: custom
      mountPath: /config/jdownloader/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jdownloader-ssd
    jellyfin:
      enabled: false
      type: custom
      mountPath: /config/jellyfin/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jellyfin-ssd
    plexmetamanager:
      enabled: false
      type: custom
      mountPath: /config/plexmetamanager/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plexmetamanager-ssd
    plexpia:
      enabled: false
      type: custom
      mountPath: /config/plex/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    plexgluetun:
      enabled: false
      type: custom
      mountPath: /config/plex/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    jfa:
      enabled: false
      type: custom
      mountPath: /config/jfa/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jfa-ssd
    joplinserver:
      enabled: false
      type: custom
      mountPath: /config/joplin-server/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-joplinserver
    kavita:
      enabled: false
      type: custom
      mountPath: /config/kavita/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-kavita-ssd
    komga:
      enabled: false
      type: custom
      mountPath: /config/komga/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-komga-ssd
    lazylibrarian:
      enabled: false
      type: custom
      mountPath: /config/lazylibrarian/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-lazylibrarian-ssd
    lidarr:
      enabled: false
      type: custom
      mountPath: /config/lidarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-lidarr-ssd
    mattermost:
      enabled: false
      type: custom
      mountPath: /config/mattermost/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-mattermost-ssd
    mylar:
      enabled: false
      type: custom
      mountPath: /config/mylar/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-mylar-ssd
    navidrome:
      enabled: false
      type: custom
      mountPath: /config/navidrome/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-navidrome-ssd
    nextpvr:
      enabled: false
      type: custom
      mountPath: /config/nextpvr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nextpvr-ssd
    notifiarr:
      enabled: false
      type: custom
      mountPath: /config/notifiarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-notifiarr-ssd
    nzbget:
      enabled: false
      type: custom
      mountPath: /config/nzbget/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nzbget-ssd
    nzbhydra:
      enabled: false
      type: custom
      mountPath: /config/nzbhydra/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nzbhydra-ssd
    ombi:
      enabled: false
      type: custom
      mountPath: /config/ombi/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-ombi-ssd
    openbooks:
      enabled: false
      type: custom
      mountPath: /config/openbooks/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-openbooks-ssd
    overseerr:
      enabled: false
      type: custom
      mountPath: /config/overseerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-overseerr-ssd
    privatebin:
      enabled: false
      type: custom
      mountPath: /config/privatebin/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-privatebin-ssd
    prowlarr:
      enabled: false
      type: custom
      mountPath: /config/prowlarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-prowlarr-ssd
    qbittorrentpia:
      enabled: false
      type: custom
      mountPath: /config/qbittorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-qbittorrent-ssd
    qbittorrentgluetun:
      enabled: false
      type: custom
      mountPath: /config/qbittorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-qbittorrent-ssd
    radarr:
      enabled: false
      type: custom
      mountPath: /config/radarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-radarr-ssd
    radarr4k:
      enabled: false
      type: custom
      mountPath: /config/radarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-radarr4k-ssd
    rapidleech:
      enabled: false
      type: custom
      mountPath: /config/rapidleech/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rapidleech-ssd
    rclonebrowser:
      enabled: true # this is always on
      type: custom
      mountPath: /config/rclonebrowser/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rclonebrowser-ssd
    readarr:
      enabled: false
      type: custom
      mountPath: /config/readarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-readarr-ssd
    readarraudio:
      enabled: false
      type: custom
      mountPath: /config/readarraudio/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-readarraudio-ssd
    resiliosync:
      enabled: false
      type: custom
      mountPath: /config/resiliosync/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-resiliosync-ssd
    rpdb:
      enabled: false
      type: custom
      mountPath: /config/rpdb/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rpdb-ssd
    rutorrentpia:
      enabled: false
      type: custom
      mountPath: /config/rutorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rutorrent-ssd
    rutorrentgluetun:
      enabled: false
      type: custom
      mountPath: /config/rutorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rutorrent-ssd
    sabnzbd:
      enabled: false
      type: custom
      mountPath: /config/sabnzbd/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sabnzbd-ssd
    seafile:
      enabled: false
      type: custom
      mountPath: /config/seafile/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-seafile
    shoko:
      enabled: false
      type: custom
      mountPath: /config/shoko/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-shoko-ssd
    sonarr:
      enabled: false
      type: custom
      mountPath: /config/sonarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sonarr-ssd
    sonarr4k:
      enabled: false
      type: custom
      mountPath: /config/sonarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sonarr4k-ssd
    syncthing:
      enabled: false
      type: custom
      mountPath: /config/syncthing/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-syncthing
    tautulli:
      enabled: false
      type: custom
      mountPath: /config/tautulli/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-tautulli-ssd
    tdarr:
      enabled: false
      type: custom
      mountPath: /config/tdarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-tdarr-ssd
    thelounge:
      enabled: false
      type: custom
      mountPath: /config/thelounge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-thelounge-ssd
    unpackerr:
      enabled: false
      type: custom
      mountPath: /config/unpackerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-unpackerr-ssd            
    uptimekuma:
      enabled: false
      type: custom
      mountPath: /config/uptimekuma/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-uptimekuma-ssd
    vaultwarden:
      enabled: false
      type: custom
      mountPath: /config/vaultwarden/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-vaultwarden-ssd
    xteve:
      enabled: false
      type: custom
      mountPath: /config/xteve/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-xteve-ssd
    youtubedl:
      enabled: false
      type: custom
      mountPath: /config/youtubedl/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-youtubedl-ssd
    rdtclient:
      enabled: false
      type: custom
      mountPath: /config/rdtclient/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rdtclient-ssd
    message:
      enabled: true
      type: emptyDir
      mountPath: /www/assets/message
    backgrounds:
      enabled: true
      type: emptyDir
      mountPath: /www/assets/backgrounds

  command:
  - /bin/bash
  - /usr/local/bin/disk_usage.sh
  additionalContainers:
    ui:
      image: ghcr.io/geek-cookbook/homer:23.10.1@sha256:0c2ffd190acc5570ef6347e4a920cd7b834e8618813f313d90bdaeddb2cec37f
      imagePullPolicy: IfNotPresent
      volumeMounts:
      - mountPath: /www/assets/config.yml
        name: config-yml
        subPath: "config.yml"
      - mountPath: /www/assets/tools.yml
        name: tools-yml
        subPath: "tools.yml"
      - mountPath: /www/assets/message
        name: message
      resources: *default_resources
      securityContext: *default_securitycontext

  initContainers:
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # This needs to be refactored into each app
        mkdir -p /storage/elfstorage/podcasts
        mkdir -p /storage/elfstorage/video
        mkdir -p /storage/elfstorage/audio
        mkdir -p /storage/elfstorage/downloads/completed/Movies
        mkdir -p /storage/elfstorage/downloads/completed/Series
        mkdir -p /storage/elfstorage/downloads/completed/Music
        mkdir -p /storage/elfstorage/downloads/completed/Books
        mkdir -p /storage/elfstorage/downloads/completed/Comics
        mkdir -p /storage/elfstorage/downloads/qbittorrent
        mkdir -p /storage/elfstorage/downloads/completed/Comics
        mkdir -p /config/filebrowser # we need this to avoid double-mounting a config file in filebrowser
      volumeMounts:
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext


  configmap:
    config:
      # -- Store homer configuration as a ConfigMap, but don't specify any config, since we'll supply our own
      enabled: false
  controller:
    replicas: 1 # not sure we need 2 replicas anymore
    strategy: RollingUpdate
    # rollingUpdate:
    #   unavailable: 1
    annotations:
      configmap.reloader.stakater.com/reload: "homer-config" # Reload the deployment every time the yaml config changes
  resources:
    requests:
      cpu: 10m
      memory: 1Mi
    limits:
      cpu: 100m
      memory: 64Mi

traefikforwardauth:
  type: wordpress
  whitelist: admin@elfhosted.com
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
  automountServiceAccountToken: false
  # Default values for traefik-forward-auth.

  controller:
    replicas: 1
    annotations:
      configmap.reloader.stakater.com/reload: traefik-forward-auth-config
    strategy: RollingUpdate
  image:
    repository: ghcr.io/geek-cookbook/traefik-forward-auth
    pullPolicy: IfNotPresent
    tag: 3.1.0@sha256:568cca312839667daaf58ae4b9fcee9efc7c9ea2d96dd8005fed57d446b5dfeb

  middleware:
    # middleware.enabled -- Enable to deploy a preconfigured middleware
    enabled: false

  envFrom:
  - configMapRef:
      name: traefik-forward-auth-config

  ingress:
    main:
      enabled: false

  service:
    main:
      enabled: true # necessary for probes

  resources:
    requests:
      cpu: 10m
      memory: 6Mi
    limits:
      cpu: 1
      memory: 32Mi

  affinity:
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app.kubernetes.io/name
            operator: In
            values:
            - traefik-forward-auth
        topologyKey: "kubernetes.io/hostname"


gatus:
  image:
    repository: ghcr.io/geek-cookbook/gatus
    tag: 5.7.0@sha256:77dd3d852b342c617eaf8d929a53020e1b2bf889b2fa16703538405294df639d
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 1m
      memory: 20Mi
    limits:
      cpu: 20m
      memory: 128Mi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  controller:
    strategy: RollingUpdate
    annotations:
      configmap.reloader.stakater.com/reload: "gatus-config"
  env:
    GATUS_CONFIG_PATH: /config/config.yaml
    SMTP_FROM: 'health@elfhosted.com'
    SMTP_PORT: 587
  persistence:
    gatus-config:
      enabled: "true"
      mountPath: /config
      type: "custom"
      volumeSpec:
        configMap:
          name: gatus-config
    data: # have to stick with this becauese of how it's named in the chart
      enabled: true
      type: custom
      mountPath: /data/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-gatus-ssd
    confighdd:
      enabled: true
      type: custom
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-gatus          
  envFrom:
  - secretRef:
      name: gatus-smtp-config
  configmap:
    config:
      # -- Store homer configuration as a ConfigMap, but don't specify any config, since we'll supply our own
      enabled: false
  initContainers:
    bootstrap-ssd:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -e

        if [[ ! -f /config/i-am-migrated ]]
        then
          if [[ ! -z "$(ls -A /config-hdd)" ]]
          then
            echo "Migrating from /config-hdd/..."
            time cp /config-hdd/* /config/ -rfpv
            touch /config/i-am-migrated
          fi
        fi

      volumeMounts:
      - mountPath: /config
        name: data
      - mountPath: /config-hdd
        name: confighdd
      env: *bootstrap_env
      resources: *default_resources
      securityContext: *default_securitycontext


gotify:
  sso:
    enabled: true
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/gotify
    tag: 2.4.0@sha256:ba635bebcbb625e17d5bf8d251be2c71f032ee80e77cbd4cbc1a6d93ee518523
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-gotify"
  automountServiceAccountToken: false
  env:
    GOTIFY_SERVER_PORT: 8080
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 1
      memory: 64Mi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /app/data/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-gotify-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-gotify
          optional: true
    tmp: *tmp # Avoids issues with readOnlyRootFilesystem
  initContainers:
    bootstrap: *bootstrap

flaresolverr:
  enabled: false
  image:
    registry: ghcr.io
    repository: flaresolverr/flaresolverr
    tag: v3.3.12
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # makes node unhappy
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-flaresolverr"
  persistence:
    <<: *appmounts
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-flaresolverr
          optional: true
    # config:
    #   enabled: true
    #   type: custom
    #   mountPath: /app/data
    #   volumeSpec:
    #     persistentVolumeClaim:
    #       claimName: config
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 1000
    runAsGroup: 1000

  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 1
      memory: 256Mi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  # initContainers:
  #   bootstrap: *bootstrap

seafile:
  enabled: false
  runtimeClassName: kata
  sso:
    enabled: false
  image:
    repository: ghcr.io/geek-cookbook/seafile
    tag: 10.0.1@sha256:24e50c4601e4c86d1521354e4dee0db18120da72f8ebbc8c4de5aa29dc07ecdb
  priorityClassName: tenant-bulk
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # doesn't seem to work with seafile, no output from container either
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    # runAsUser: 568 # has to run as root, see https://github.com/haiwen/seafile-docker/issues/86
    # runAsGroup: 568
  automountServiceAccountToken: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-seafile"
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 1024m
      memory: 512Mi
  env:
    # -- Set the container timezone
    TIME_ZONE: Etc/UTC
    # -- The hostname of your database
    DB_HOST: "{{ .Release.Name }}-seafile-mysql"
    # -- The root password for mysql (used for initial setup)
    DB_ROOT_PASSWD: wLu5UUuT@3Zu33eT
    # -- The initial admin user's password
    SEAFILE_ADMIN_PASSWORD: changeme
    # -- The hostname for the server (set to your ingress hostname)
    SEAFILE_SERVER_HOSTNAME: "{{ .Release.Name }}-seafile.elfhosted.com"
    SEAFILE_SERVER_LETSENCRYPT: false
    FORCE_HTTPS_IN_CONF: true
    NON_ROOT: true # yes, and with our custom image, this runs the seafile/seahub components as user 568
  envFrom:
  - configMapRef:
      name: seafile-config
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # debug whether this gets us probes
  memcached:
    nameOverride: seafile-memcached
    enabled: true
  mysql:
    nameOverride: seafile-mysql
    enabled: true
    architecture: standalone
    commonAnnotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-seafile"

    auth:
      rootPassword: "wLu5UUuT@3Zu33eT"
      database: "seafile"
      username: "seafile"
      password: "nXCXSmqU4TMk3okD"

    primary:
      readinessProbe:
        enabled: false # probes can make helm fail/restart under some conditions. Either do or do not, there is no try
      livenessProbe:
        enabled: false # probes can make helm fail/restart under some conditions. Either do or do not, there is no try
      startupProbe:
        enabled: false # probes can make helm fail/restart under some conditions. Either do or do not, there is no try
      persistence:
        enabled: true
        existingClaim: config-seafile
        subPath: database
      resources:
        requests:
          cpu: 5m
          memory: 1Gi
        limits:
          cpu: 2
          memory: 1024Mi
      containerSecurityContext:
        enabled: true
        seccompProfile:
          type: RuntimeDefault
        runAsUser: 568
        runAsGroup: 568
      podSecurityContext:
        enabled: true
        runAsUser: 568
        runAsGroup: 568
        fsGroup: 568
      extraVolumeMounts:
      - mountPath: /opt/bitnami/mysql/tmp/
        name: tmp
      extraVolumes:
      - name: tmp
        emptyDir:
          sizeLimit: 1Gi
      - name: backup-database-script
        configMap:
          name: seafile-backup
      - name: elfstorage
        persistentVolumeClaim:
          claimName: elfstorage
      sidecars:
        - name: backup-database
          image: *tooling_image
          env:
            - name: MYSQL_ROOT_PASSWORD
              value: wLu5UUuT@3Zu33eT
            - name: MYSQL_DATABASE
              value: seafile
          volumeMounts:
          - mountPath: /backup
            name: elfstorage
            subPath: backup/seafile
          command:
          - /usr/bin/dumb-init
          - /bin/bash
          - -c
          - |

            sleep 2m # give mysql time to start up
            while true
            do
              now=$(date +"%s_%Y-%m-%d")
              /usr/bin/mysqldump --opt -h seafile-mysql -u root -p${MYSQL_ROOT_PASSWORD} ${MYSQL_DATABASE} > "/backup/${now}_${MYSQL_DATABASE}.sql"
              sleep 1d
            done
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /shared/seafile
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-seafile
      subPath: data
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-seafile
          optional: true
  initContainers:
    bootstrap: *bootstrap

xteve:
  enabled: false
  sso:
    enabled: true
  image:
    registry: ghcr.io
    repository: k8s-at-home/xteve
    tag: v2.2.0.200
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-xteve"
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 1
      memory: 1Gi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: false # necessary for probes
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-xteve-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-xteve
          optional: true
  initContainers:
    bootstrap: *bootstrap

youtubedl:
  enabled: false
  sso:
    enabled: true
  image:
    repository: ghcr.io/geek-cookbook/youtubedl-material-nightly
    tag: "4.3.2@sha256:057a172284fdb540a79e42a2afe92ac2431db53a7bbc126be1d2653b0ca46a07"
  priorityClassName: tenant-bulk
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # doesn't work because the node modules in /app try to create files
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-youtubedl"
  env:
    TZ: UTC
  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 128Mi
    limits:
      cpu: 10
      memory: 1024Mi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: false # necessary for probes
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /app/appdata
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-youtubedl-ssd
    pm2:
      enabled: true
      mountPath: /app/pm2
      type: emptyDir
      volumeSpec:
        medium: Memory
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-youtubedl
          optional: true

  initContainers:
    bootstrap: *bootstrap

thelounge:
  enabled: false
  sso:
    enabled: true
  image:
    repository: ghcr.io/geek-cookbook/thelounge
    tag: "4.4.1@sha256:26c87c70f7f1a6d020232c81ff2ff051dcf57a652ea09d8950d6a066ab358b28"
  priorityClassName: tenant-normal
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-thelounge"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true # doesn't work because the node modules in /app try to create files
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  env:
    TZ: UTC
    THELOUNGE_HOME: /config/thelounge # avoids attempts to chown /config
  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 40Mi
    limits:
      cpu: 100m
      memory: 1024Mi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-thelounge-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-thelounge
          optional: true
  initContainers:
    bootstrap: *bootstrap
    create-user:
      image: ghcr.io/geek-cookbook/thelounge:4.4.1@sha256:26c87c70f7f1a6d020232c81ff2ff051dcf57a652ea09d8950d6a066ab358b28
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e


        # If we don't already have a config, create one
        if [ ! -f /config/thelounge/config.json ];
        then
          mkdir -p /config/thelounge
          cp /config-bootstrap/* /config/thelounge/ -R
        fi

        # If we don't already have a user, create one
        if [ ! -f /config/thelounge/users/${USERNAME}.json ];
        then
          thelounge add ${USERNAME} --password ${PASSWORD}
        fi
      volumeMounts:
      - mountPath: /config
        name: config
      env:
      - name: THELOUNGE_HOME
        value: /config/thelounge # avoids attempts to chown /config
      - name: USERNAME
        valueFrom:
          configMapKeyRef:
            name: elfhosted-user-config
            key: USERNAME
      - name: PASSWORD
        value: ireadthedocs
      securityContext:
        seccompProfile:
          type: RuntimeDefault
        readOnlyRootFilesystem: true


unpackerr:
  enabled: false
  sso:
    enabled: true
  image:
    repository: ghcr.io/geek-cookbook/unpackerr
    tag: 0.12.0@sha256:a452fa96e01ac2387f657abd3d2054889ba546b15a5aa5ddd66b88d731a37b61
  priorityClassName: tenant-bulk
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-unpackerr"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true # doesn't work because the node modules in /app try to create files
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  env:
    # Avoid users using this to run commands?
    UN_CMDHOOK_0_COMMAND: /bin/true

  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 16Mi
    limits:
      cpu: 500m
      memory: 1024Mi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
      ports:
        http:
          port: 9898 # doesn't matter this doesn,t actually use ports
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-unpackerr-ssd
    example-config:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: unpackerr-config
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-unpackerr
          optional: true

  initContainers:
    bootstrap: *bootstrap
    copy-example-config:
      image: ghcr.io/geek-cookbook/unpackerr@sha256:014440a2a7e4499a9ce52be1388567d24fc515d8d00422434239b918c56a717a
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # If we don't already have an example config, create one
        if [ ! -f /config/unpackerr.conf ];
        then
          cp /bootstrap/unpackerr.conf /config/
        fi
      volumeMounts:
      - mountPath: /config
        name: config
      - name: example-config
        mountPath: "/bootstrap/"
      securityContext:
        seccompProfile:
          type: RuntimeDefault
        readOnlyRootFilesystem: true
  additionalContainers:
    podinfo:
      image: stefanprodan/podinfo # used to run probes from gatus

overseerr:
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/overseerr
    tag: 1.33.2@sha256:07004541caa460eb70626dc73831032f35267eed98cbff5972b7b8ce5fe1a635
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-overseerr"
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    runAsNonRoot: true
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  sso:
    enabled: true
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-overseerr-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-overseerr
          optional: true
    tmp: *tmp
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes # need this for probes?
  resources:
    requests:
      cpu: 10m
      memory: 175Mi
    limits:
      cpu: 2
      memory: 1Gi

jellyseerr:
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/jellyseerr
    tag: 1.7.0@sha256:73e7f3b0c57d785d709412e8c96cb722529e37578e6e38d94ab8874bedcb3758
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-jellyseerr"
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    runAsNonRoot: true
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  sso:
    enabled: true
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jellyseerr-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-jellyseerr
          optional: true
    tmp: *tmp
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes # need this for probes?
  resources:
    requests:
      cpu: 10m
      memory: 160Mi
    limits:
      cpu: 2
      memory: 1Gi

audiobookshelf:
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/audiobookshelf
    tag: 2.6.0@sha256:974b0e083a19b59b0cd6e521906886d242b0c68832d28f7f58d00d1afe823f33
  priorityClassName: tenant-streaming
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    runAsNonRoot: true
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-audiobookshelf,elfbot-all"
  sso:
    enabled: true
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-audiobookshelf-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-audiobookshelf
          optional: true
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes # need this for probes?
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 2
      memory: 1Gi

openbooks:
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/openbooks
    tag: 4.5.0@sha256:1bab9fbe69224c80f3a0fa8b715e4f708edbed49999e29b564f0b203de46a5b9
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    runAsNonRoot: true
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  command:
  - /bin/bash
  - -c
  - |
    set -x
    set -e
    sleep 5s
    USER=$(tr -dc A-Za-z0-9 </dev/urandom | head -c 13 ; echo '')
    ./openbooks server \
      --dir /storage/elfstorage/downloads/completed \
      --port 8000 \
      --name $USER \
      --tls=false \
      --persist \
      --server irc.irchighway.net:6661 \
      --no-browser-downloads \
      --debug
  automountServiceAccountToken: false
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-openbooks"
  sso:
    enabled: true
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-openbooks-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-openbooks
          optional: true
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes # need this for probes?
  resources:
    requests:
      cpu: 10m
      memory: 64Mi
    limits:
      cpu: 2
      memory: 1Gi

vaultwarden:
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/vaultwarden
    tag: 1.30.1@sha256:41260dfcc2764421aabf70592a70430cfa6ae28799aaf2dd3f29cea3dceb1eee
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    runAsNonRoot: true
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-vaultwarden"
  automountServiceAccountToken: false
  sso:
    enabled: true
  envFrom:
  - configMapRef:
      name: elfbot-vaultwarden
      optional: true
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /data
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-vaultwarden-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-vaultwarden
          optional: true
    tmp: *tmp
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes # need this for probes?
  resources:
    requests:
      cpu: 10m
      memory: 16Mi
    limits:
      cpu: 1
      memory: 1Gi


notifiarr:
  enabled: false
  sso:
    enabled: true
  hostname: elfhosted
  image:
    repository: ghcr.io/geek-cookbook/notifiarr
    tag: 0.7.0@sha256:7cb46eccf4a57f329f4de970126de4ddbe5da3898836f293c69948d59260bea2
  priorityClassName: tenant-normal
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true # doesn't work because the node modules in /app try to create files
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-notifiarr"
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"

  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 16Mi
    limits:
      cpu: 2
      memory: 1024Mi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: false # necessary for probes
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-notifiarr-ssd
    example-config:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: notifiarr-config
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-notifiarr
          optional: true
  initContainers:
    bootstrap: *bootstrap
    copy-example-config:
      image: ghcr.io/geek-cookbook/notifiarr:0.7.0@sha256:7cb46eccf4a57f329f4de970126de4ddbe5da3898836f293c69948d59260bea2
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # If we don't already have an example config, create one
        if [ ! -f /config/notifiarr.conf ];
        then
          cp /bootstrap/notifiarr.conf /config/
        fi
      volumeMounts:
      - mountPath: /config
        name: config
      - name: example-config
        mountPath: "/bootstrap/"
      securityContext:
        seccompProfile:
          type: RuntimeDefault
        readOnlyRootFilesystem: true

shoko:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/shokoserver
    tag: v4.2.2@sha256:851c185c96dd0a05af2c73809748a96ebf5c7728e4d4dd175da7e80c4d61287b
  env:
    PUID: 568
    PGID: 568
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-shoko"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true # again, s6
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /home/shoko/.shoko/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-shoko-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-shoko
          optional: true
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 256Mi
    limits:
      cpu: 1
      memory: 1Gi

filebot:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/filebot-node
    tag: 0.4.6@sha256:c3f1cde643009765fcec62d4bf68f2ed26e3218fb259fac839b9c3ff055ce949
  env:
    PUID: 568
    PGID: 568
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-filebot"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true # again, s6
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /data
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-filebot-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-filebot
          optional: true

    tmp: # to avoid errors about storing java prefs
      enabled: true
      type: emptyDir
      mountPath: /home/seedy
      sizeLimit: 1Gi
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 16Mi
    limits:
      cpu: 2
      memory: 1Gi

nextpvr:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-streaming
  image:
    repository: ghcr.io/geek-cookbook/nextpvr
    tag: 10.8.13@sha256:2f4b91dc4e638f7ca1ddf2a5955d11854738f0994eb4ffe65cc9549f4ca87ee9
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-nextpvr"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    runAsUser: 568
    runAsGroup: 568
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nextpvr-ssd
    recordings:
      enabled: true
      type: emptyDir
      mountPath: /recordings
      sizeLimit: 1Gi
    buffer:
      enabled: true
      type: emptyDir
      mountPath: /buffer
      sizeLimit: 1Gi
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-nextpvr
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 16Mi
    limits:
      cpu: 2
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap

rpdb:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/rpdb
    tag: 0.2.7@sha256:79df0fc8dc74918a3c09154fb759a509cab218e80794765b1b44d5ee4a8bbdb9
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-rpdb"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /.config
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rpdb-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-rpdb
          optional: true
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 40Mi
    limits:
      cpu: 1
      memory: 1Gi

plexmetamanager:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/plex-meta-manager
    tag: v1.19.0@sha256:5847501532029eafe42a4d275c9e57999903bf6f2f41c1afa62cba9a4973f4cf
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-plexmetamanager"
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  service:
    main:
      enabled: true # necessary for probes
      ports:
        http:
          port: 9898 # doesn't matter this doesn,t actually use ports
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /app/config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plexmetamanager-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-plexmetamanager
          optional: true

    example-config:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: plexmetamanager-config
  initContainers:
    bootstrap: *bootstrap
    copy-example-config:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # If we don't already have an example config, create one
        if [ ! -f /app/config/config.yml ];
        then
          cp /bootstrap/config.yml /app/config/
        fi
      volumeMounts:
      - mountPath: /app/config
        name: config
      - name: example-config
        mountPath: "/bootstrap/"
      securityContext:
        seccompProfile:
          type: RuntimeDefault
        readOnlyRootFilesystem: true
  ingress:
    main:
      enabled: false
  resources:
    requests:
      cpu: 10m
      memory: 150Mi
    limits:
      cpu: 1
      memory: 1Gi
  probes:
    liveness:
      enabled: false
    readiness:
      enabled: false
    startup:
      enabled: false
  additionalContainers:
    podinfo:
      image: stefanprodan/podinfo # used to run probes from gatus

rclonewebdav:
  enabled: false # we need a default

rclonebrowser:
  podLabels:
    app.elfhosted.com/name: rclonebrowser
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/rclone
    tag: 1.65.0@sha256:ce52d989e6a46c101c5ef8f69529bcab3c2a946266866671a2b36435a9d7f81d
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-rclonebrowser,elfbot-rcloneui,elfbot-rclonefm,rclonefm-config,elfhosted-user-config"
  podAnnotations:
    kubernetes.io/egress-bandwidth: "10M"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # s6 and the way this is built prevents this currently
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    # runAsUser: 568 # runs s6 currently
    # runAsGroup: 568
    # fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
    nodeTaintsPolicy: Honor
    labelSelector: 
      matchLabels: 
        app.elfhosted.com/name: rclonebrowser        
  automountServiceAccountToken: false
  env:
    APP_NICENESS: 19 # run at lowest niceness
    S6_READ_ONLY_ROOT: 1
    USER_ID: 568
    GROUP_ID: 568
  envFrom:
  - configMapRef:
      name: elfhosted-user-config
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rclonebrowser-ssd
    rclonefm-config:
      enabled: "true"
      mountPath: /var/lib/rclonefm/js/settings.js
      subPath: "settings.js"
      type: "custom"
      volumeSpec:
        configMap:
          name: rclonefm-config
    rclone-remote-storage:
      enabled: "true"
      subPath: "rclone-remote-storage"
      type: "custom"
      volumeSpec:
        configMap:
          name: rclonefm-config          
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-rclonebrowser
          optional: true

    # We need one of these per-app. The global section will override the false enablement
    autobrr:
      enabled: false
      type: custom
      mountPath: /storage/config/autobrr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-autobrr-ssd
    autoscan:
      enabled: false
      type: custom
      mountPath: /storage/config/autoscan/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-autoscan-ssd            
    audiobookshelf:
      enabled: false
      type: custom
      mountPath: /storage/config/audiobookshelf/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-audiobookshelf-ssd
    bazarr:
      enabled: false
      type: custom
      mountPath: /storage/config/bazarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-bazarr-ssd
    bazarr4k:
      enabled: false
      type: custom
      mountPath: /storage/config/bazarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-bazarr4k-ssd
    calibreweb:
      enabled: false
      type: custom
      mountPath: /storage/config/calibreweb/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-calibreweb-ssd
    calibre:
      enabled: false
      type: custom
      mountPath: /storage/config/calibre/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-calibre-ssd
    delugepia:
      enabled: false
      type: custom
      mountPath: /storage/config/deluge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-deluge-ssd
    delugegluetun:
      enabled: false
      type: custom
      mountPath: /storage/config/deluge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-deluge-ssd
    emby:
      enabled: false
      type: custom
      mountPath: /storage/config/emby/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-emby-ssd
    filebot:
      enabled: false
      type: custom
      mountPath: /storage/config/filebot/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-filebot-ssd
    gotify:
      enabled: false
      type: custom
      mountPath: /storage/config/gotify/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-gotify-ssd          
    homepage:
      enabled: false
      type: custom
      mountPath: /storage/config/homepage/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-homepage-ssd
    jellyseerr:
      enabled: false
      type: custom
      mountPath: /storage/config/jellyseerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jellyseerr-ssd
    pyload:
      enabled: false
      type: custom
      mountPath: /storage/config/pyload/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-pyload-ssd
    jdownloader:
      enabled: false
      type: custom
      mountPath: /storage/config/jdownloader/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jdownloader-ssd          
    jellyfin:
      enabled: false
      type: custom
      mountPath: /storage/config/jellyfin/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jellyfin-ssd
    plexmetamanager:
      enabled: false
      type: custom
      mountPath: /storage/config/plexmetamanager/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plexmetamanager-ssd
    plexpia:
      enabled: false
      type: custom
      mountPath: /storage/config/plex/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    plexgluetun:
      enabled: false
      type: custom
      mountPath: /storage/config/plex/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-plex-ssd
    joplinserver:
      enabled: false
      type: custom
      mountPath: /storage/config/joplin-server/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-joplinserver
    jfa:
      enabled: false
      type: custom
      mountPath: /storage/config/jfa/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jfa-ssd
    kavita:
      enabled: false
      type: custom
      mountPath: /storage/config/kavita/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-kavita-ssd
    komga:
      enabled: false
      type: custom
      mountPath: /storage/config/komga/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-komga-ssd
    lazylibrarian:
      enabled: false
      type: custom
      mountPath: /storage/config/lazylibrarian/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-lazylibrarian-ssd
    lidarr:
      enabled: false
      type: custom
      mountPath: /storage/config/lidarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-lidarr-ssd
    mattermost:
      enabled: false
      type: custom
      mountPath: /storage/config/mattermost/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-mattermost-ssd
    mylar:
      enabled: false
      type: custom
      mountPath: /storage/config/mylar/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-mylar-ssd
    navidrome:
      enabled: false
      type: custom
      mountPath: /storage/config/navidrome/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-navidrome-ssd
    nextpvr:
      enabled: false
      type: custom
      mountPath: /storage/config/nextpvr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nextpvr-ssd
    notifiarr:
      enabled: false
      type: custom
      mountPath: /storage/config/notifiarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-notifiarr-ssd
    nzbget:
      enabled: false
      type: custom
      mountPath: /storage/config/nzbget/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nzbget-ssd
    nzbhydra:
      enabled: false
      type: custom
      mountPath: /storage/config/nzbhydra/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-nzbhydra-ssd
    ombi:
      enabled: false
      type: custom
      mountPath: /storage/config/ombi/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-ombi-ssd
    openbooks:
      enabled: false
      type: custom
      mountPath: /storage/config/openbooks/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-openbooks-ssd
    overseerr:
      enabled: false
      type: custom
      mountPath: /storage/config/overseerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-overseerr-ssd
    privatebin:
      enabled: false
      type: custom
      mountPath: /storage/config/privatebin/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-privatebin-ssd
    prowlarr:
      enabled: false
      type: custom
      mountPath: /storage/config/prowlarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-prowlarr-ssd
    qbittorrentpia:
      enabled: false
      type: custom
      mountPath: /storage/config/qbittorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-qbittorrent-ssd
    qbittorrentgluetun:
      enabled: false
      type: custom
      mountPath: /storage/config/qbittorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-qbittorrent-ssd
    radarr:
      enabled: false
      type: custom
      mountPath: /storage/config/radarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-radarr-ssd
    radarr4k:
      enabled: false
      type: custom
      mountPath: /storage/config/radarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-radarr4k-ssd
    rapidleech:
      enabled: false
      type: custom
      mountPath: /storage/config/rapidleech/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rapidleech-ssd
    readarr:
      enabled: false
      type: custom
      mountPath: /storage/config/readarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-readarr-ssd
    readarraudio:
      enabled: false
      type: custom
      mountPath: /storage/config/readarraudio/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-readarraudio-ssd
    resiliosync:
      enabled: false
      type: custom
      mountPath: /storage/config/resiliosync/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-resiliosync-ssd
    rpdb:
      enabled: false
      type: custom
      mountPath: /storage/config/rpdb/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rpdb-ssd
    rutorrentpia:
      enabled: false
      type: custom
      mountPath: /storage/config/rutorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rutorrent-ssd
    rutorrentgluetun:
      enabled: false
      type: custom
      mountPath: /storage/config/rutorrent/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rutorrent-ssd
    sabnzbd:
      enabled: false
      type: custom
      mountPath: /storage/config/sabnzbd/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sabnzbd-ssd
    seafile:
      enabled: false
      type: custom
      mountPath: /storage/config/seafile/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-seafile
    shoko:
      enabled: false
      type: custom
      mountPath: /storage/config/shoko/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-shoko-ssd
    sonarr:
      enabled: false
      type: custom
      mountPath: /storage/config/sonarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sonarr-ssd
    sonarr4k:
      enabled: false
      type: custom
      mountPath: /storage/config/sonarr4k/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-sonarr4k-ssd
    syncthing:
      enabled: false
      type: custom
      mountPath: /storage/config/syncthing/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-syncthing
    tautulli:
      enabled: false
      type: custom
      mountPath: /storage/config/tautulli/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-tautulli-ssd
    tdarr:
      enabled: false
      type: custom
      mountPath: /storage/config/tdarr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-tdarr-ssd
    thelounge:
      enabled: false
      type: custom
      mountPath: /storage/config/thelounge/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-thelounge-ssd
    unpackerr:
      enabled: false
      type: custom
      mountPath: /storage/config/unpackerr/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-unpackerr-ssd          
    uptimekuma:
      enabled: false
      type: custom
      mountPath: /storage/config/uptimekuma/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-uptimekuma-ssd
    vaultwarden:
      enabled: false
      type: custom
      mountPath: /storage/config/vaultwarden/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-vaultwarden-ssd
    xteve:
      enabled: false
      type: custom
      mountPath: /storage/config/xteve/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-xteve-ssd
    youtubedl:
      enabled: false
      type: custom
      mountPath: /storage/config/youtubedl/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-youtubedl-ssd
    rdtclient:
      enabled: false
      type: custom
      mountPath: /storage/config/rdtclient/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rdtclient-ssd

  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # add local remote if it doesn't exist
        grep -q '/storage' /config/rclone.conf || cat /rclone-remote-storage >> /config/rclone.conf

      volumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /tmp # need this for cating into a file
        name: tmp        
      - mountPath: /rclone-remote-storage
        subPath: rclone-remote-storage
        name: rclone-remote-storage
      resources: *default_resources
      securityContext: *default_securitycontext
  service:
    main:
      enabled: false # necessary for probes
      ports:
        http:
          port: 5572
  ingress:
    main:
      enabled: false
  resources:
    requests:
      cpu: 1m
      memory: 60Mi
    limits:
      cpu: 150m
      memory: 256Mi

jfa:
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/jfa-go
    tag: v1.19.1@sha256:6d632df6c28d310035ebfc58263586f223417f45ac29214ca23410ea4b12d331
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-jfa"
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    elfstorage: *elfstorage
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jfa-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-jfa
          optional: true
    tmp:
      enabled: true
      type: emptyDir
      mountPath: /tmp
      sizeLimit: 1Gi
  initContainers:
    bootstrap: *bootstrap
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 150Mi
    limits:
      cpu: 2
      memory: 1Gi

mattermost:
  enabled: false
  # Default values for mattermost-team-edition.
  # This is a YAML-formatted file.
  # Declare variables to be passed into your templates.
  image:
    repository: mattermost/mattermost-team-edition
    tag: 9.3.0@sha256:8fb8b996faf06ecb5aa963027170c27d530d9bd6eb27d6e44ab0215706493c4f
    imagePullPolicy: IfNotPresent
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-mattermost"

  initContainerImage:
    repository: appropriate/curl
    tag: latest
    imagePullPolicy: IfNotPresent

  extraInitContainers:
  - name: migrate-database
    image: *tooling_image
    imagePullPolicy: IfNotPresent
    command:
    - /bin/bash
    - -c
    - |
      set -e

      if [[ ! -f /config/i-am-migrated ]]
      then
        if [[ ! -z "$(ls -A /config-hdd)" ]]
        then
          echo "Migrating from /config-hdd/..."
          time cp /config-hdd/* /config/ -rfpv
          touch /config/i-am-migrated
        fi
      fi
    volumeMounts:
    - mountPath: /config
      name: mattermost-data
      subPath: data
    - mountPath: /config-hdd
      name: confighdd
      subPath: data
    env: *bootstrap_env
    resources: *default_resources
    securityContext: *default_securitycontext


  ## Deployment Strategy
  ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#strategy
  deploymentStrategy:
    type: Recreate
    rollingUpdate: null

  ## How many old ReplicaSets for Mattermost Deployment you want to retain
  revisionHistoryLimit: 1

  ## Enable persistence using Persistent Volume Claims
  ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
  ## ref: https://docs.gitlab.com/ee/install/requirements.html#storage
  ##
  persistence:
    ## This volume persists generated data from users, like images, attachments...
    ##
    data:
      enabled: true
      size: 10Gi
      ## If defined, volume.beta.kubernetes.io/storage-class: <storageClass>
      ## Default: volume.alpha.kubernetes.io/storage-class: default
      ##
      # storageClass:
      accessMode: ReadWriteOnce
      existingClaim: "config-mattermost-ssd"
      subPath: data
    plugins:
      enabled: false # these just end up under data anyway

  service:
    type: ClusterIP
    externalPort: 8065
    internalPort: 8065
    annotations: {}
    # loadBalancerIP:
    loadBalancerSourceRanges: []

  ingress:
    enabled: false
    path: /
    annotations: {}
      # kubernetes.io/ingress.class: nginx
      # certmanager.k8s.io/issuer:  your-issuer
      # nginx.ingress.kubernetes.io/proxy-body-size: 50m
      # nginx.ingress.kubernetes.io/proxy-send-timeout: "600"
      # nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
      # nginx.ingress.kubernetes.io/proxy-buffering: "on"
      # nginx.ingress.kubernetes.io/configuration-snippet: |
      #   proxy_cache mattermost_cache;
      #   proxy_cache_revalidate on;
      #   proxy_cache_min_uses 2;
      #   proxy_cache_use_stale timeout;
      #   proxy_cache_lock on;
      #### To use the nginx cache you will need to set an http-snippet in the ingress-nginx configmap
      #### http-snippet: |
      ####     proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=mattermost_cache:10m max_size=3g inactive=120m use_temp_path=off;
    hosts:
      - mattermost.example.com
    tls:
      # - secretName: mattermost.example.com-tls
      #   hosts:
      #     - mattermost.example.com

  route:
    enabled: false

  ## If use this please disable the mysql chart by setting mysql.enable to false
  externalDB:
    enabled: true

    ## postgres or mysql
    externalDriverType: "mysql"

    ## postgres:  "<USERNAME>:<PASSWORD>@<HOST>:5432/<DATABASE_NAME>?sslmode=disable&connect_timeout=10"
    ## mysql:     "<USERNAME>:<PASSWORD>@tcp(<HOST>:3306)/<DATABASE_NAME>?charset=utf8mb4,utf8&readTimeout=30s&writeTimeout=30s"
    externalConnectionString: "mattermost:IUzI1NiJ9.eyJhdWQiOiIwMDk1MTkyYjhjZWIyYjVhNDQwMT@tcp(mattermost-mysql:3306)/mattermost?charset=utf8mb4,utf8&readTimeout=30s&writeTimeout=30s"

  mysql:
    nameOverride: mattermost-mysql
    enabled: true
    architecture: standalone
    # nameOverride: mattermost-mariadb

    commonAnnotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-mattermost"

    auth:
      rootPassword: "3uAaJYGJLR3d2qbBM2FsSThJ"
      database: "mattermost"
      username: "mattermost"
      password: "IUzI1NiJ9.eyJhdWQiOiIwMDk1MTkyYjhjZWIyYjVhNDQwMT"

    primary:
      initContainers: *bootstrap_migrate_db    
      readinessProbe:
        enabled: false # probes can make helm fail/restart under some conditions. Either do or do not, there is no try
      livenessProbe:
        enabled: false # probes can make helm fail/restart under some conditions. Either do or do not, there is no try
      startupProbe:
        enabled: false # probes can make helm fail/restart under some conditions. Either do or do not, there is no try
      persistence:
        enabled: true
        existingClaim: config-mattermost-ssd
        subPath: database
      resources:
        requests:
          cpu: 5m
          memory: 1Gi
        limits:
          cpu: 2
          memory: 1024Mi
      containerSecurityContext:
        enabled: true
        seccompProfile:
          type: RuntimeDefault
        runAsUser: 568
        runAsGroup: 568
      podSecurityContext:
        enabled: true
        runAsUser: 568
        runAsGroup: 568
        fsGroup: 568
      extraVolumeMounts:
      - mountPath: /opt/bitnami/mysql/tmp/
        name: tmp
      extraVolumes:
      - name: tmp
        emptyDir:
          sizeLimit: 1Gi
      - name: backup-database-script
        configMap:
          name: mattermost-backup
      - name: elfstorage
        persistentVolumeClaim:
          claimName: elfstorage
      - name: confighdd
        persistentVolumeClaim:
          claimName: config-mattermost
          subPath: database
      sidecars:
        - name: backup-database
          image: *tooling_image
          env:
            - name: MYSQL_ROOT_PASSWORD
              value: 3uAaJYGJLR3d2qbBM2FsSThJ
            - name: MYSQL_DATABASE
              value: mattermost
          volumeMounts:
          - mountPath: /backup
            name: elfstorage
            subPath: backup/mattermost
          command:
          - /usr/bin/dumb-init
          - /bin/bash
          - -c
          - |

            sleep 2m # give mysql time to start up
            while true
            do
              now=$(date +"%s_%Y-%m-%d")
              /usr/bin/mysqldump --opt -h mattermost-mysql -u root -p${MYSQL_ROOT_PASSWORD} ${MYSQL_DATABASE} > "/backup/${now}_${MYSQL_DATABASE}.sql"
              sleep 1d
            done

  ## Additional pod annotations
  extraPodAnnotations: {}

  ## Additional env vars
  extraEnvVars: []
    # This is an example of extra env vars when using with the deployment with GitLab Helm Charts
    # - name: POSTGRES_PASSWORD_GITLAB
    #   valueFrom:
    #     secretKeyRef:
    #       # NOTE: Needs to be manually created
    #       # kubectl create secret generic gitlab-postgresql-password --namespace <NAMESPACE> --from-literal postgres-password=<PASSWORD>
    #       name: gitlab-postgresql-password
    #       key: postgres-password
    # - name: POSTGRES_USER_GITLAB
    #   value: gitlab
    # - name: POSTGRES_HOST_GITLAB
    #   value: gitlab-postgresql
    # - name: POSTGRES_PORT_GITLAB
    #   value: "5432"
    # - name: POSTGRES_DB_NAME_MATTERMOST
    #   value: mm5
    # - name: MM_SQLSETTINGS_DRIVERNAME
    #   value: "postgres"
    # - name: MM_SQLSETTINGS_DATASOURCE
    #   value: postgres://$(POSTGRES_USER_GITLAB):$(POSTGRES_PASSWORD_GITLAB)@$(POSTGRES_HOST_GITLAB):$(POSTGRES_PORT_GITLAB)/$(POSTGRES_DB_NAME_MATTERMOST)?sslmode=disable&connect_timeout=10

  ## Additional init containers
  extraInitContainers: []
    # This is an example of extra Init Container when using with the deployment with GitLab Helm Charts
    # - name: bootstrap-database
    #   image: "postgres:9.6-alpine"
    #   imagePullPolicy: IfNotPresent
    #   env:
    #     - name: POSTGRES_PASSWORD_GITLAB
    #       valueFrom:
    #         secretKeyRef:
    #           name: gitlab-postgresql-password
    #           key: postgres-password
    #     - name: POSTGRES_USER_GITLAB
    #       value: gitlab
    #     - name: POSTGRES_HOST_GITLAB
    #       value: gitlab-postgresql
    #     - name: POSTGRES_PORT_GITLAB
    #       value: "5432"
    #     - name: POSTGRES_DB_NAME_MATTERMOST
    #       value: mm5
    #   command:
    #     - sh
    #     - "-c"
    #     - |
    #       if PGPASSWORD=$POSTGRES_PASSWORD_GITLAB psql -h $POSTGRES_HOST_GITLAB -p $POSTGRES_PORT_GITLAB -U $POSTGRES_USER_GITLAB -lqt | cut -d \| -f 1 | grep -qw $POSTGRES_DB_NAME_MATTERMOST; then
    #       echo "database already exist, exiting initContainer"
    #       exit 0
    #       else
    #       echo "Database does not exist. creating...."
    #       PGPASSWORD=$POSTGRES_PASSWORD_GITLAB createdb -h $POSTGRES_HOST_GITLAB -p $POSTGRES_PORT_GITLAB -U $POSTGRES_USER_GITLAB $POSTGRES_DB_NAME_MATTERMOST
    #       echo "Done"
    #       fi

  # Add additional volumes and mounts, for example to add SAML keys in the app or other files the app server may need to access
  extraVolumes: []
    # - hostPath:
    #     path: /var/log
    #   name: varlog
  extraVolumeMounts: []
    # - name: varlog
    #   mountPath: /host/var/log
    #   readOnly: true

  ## Node selector
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
  nodeSelector: {}

  ## Affinity
  ## ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
  affinity: {}

  ## Tolerations for pod assignment
  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
  tolerations: []

  ## Pod Security Context
  ## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/
  securityContext:
    fsGroup: 2000
    runAsGroup: 2000
    runAsUser: 2000

  serviceAccount:
    create: false
    name:
    annotations: {}

  ## Configuration
  ## The config here will be injected as environment variables in the deployment
  ## Please refer to https://docs.mattermost.com/administration/config-settings.html#configuration-in-database for more information
  ## You can add any config here, but need to respect the format: MM_<GROUPSECTION>_<SETTING>. ie: MM_SERVICESETTINGS_ENABLECOMMANDS: false
  config:
    MM_PLUGINSETTINGS_CLIENTDIRECTORY: "./client/plugins"

rapidleech:
  runtimeClassName: kata
  enabled: false
  sso:
    enabled: true
  priorityClassName: tenant-bulk
  image:
    repository: ghcr.io/geek-cookbook/rapidleech
    tag: rolling@sha256:a7b5ccdf923a401870a744c41649b73513cfe923e8ee15a7cc2075293a5a3670
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-rapidleech"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    runAsUser: 568
    runAsGroup: 568
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  persistence:
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rapidleech-ssd
    data:
      enabled: false
    elfstorage:
      enabled: true
      type: custom
      mountPath: /var/www/html/files
      volumeSpec:
        persistentVolumeClaim:
          claimName: elfstorage
          subPath: downloads/completed
    var-run:
      enabled: true
      mountPath: /var/run/
      type: emptyDir
      volumeSpec:
        medium: Memory
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-rapidleech
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 96Mi
    limits:
      cpu: 10m
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # We need this file to exist
        touch /config/files.lst
        mkdir -p /storage/elfstorage/downloads/completed
      volumeMounts:
      - mountPath: /config
        name: config
      - mountPath: /storage/elfstorage
        name: elfstorage
      resources: *default_resources
      securityContext: *default_securitycontext

syncthing:
  enabled: false
  hostname: elfhosted
  sso:
    enabled: true
  priorityClassName: tenant-bulk
  image:
    repository: ghcr.io/geek-cookbook/syncthing
    tag: 1.23.6@sha256:1d41216dee7406ba4e3bfd2310023e5a7a6146fcabcbcc039259b6c64f3e4364
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-syncthing"
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists      
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-syncthing
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-syncthing
          optional: true

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 10Mi
    limits:
      cpu: 1
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap
    setup:
      image: ghcr.io/geek-cookbook/syncthing:1.23.6@sha256:1d41216dee7406ba4e3bfd2310023e5a7a6146fcabcbcc039259b6c64f3e4364
      imagePullPolicy: IfNotPresent
      envFrom:
      - configMapRef:
          name: elfhosted-user-config
      command:
      - /bin/ash
      - -c
      - |
        set -x
        set -e

        # Generate a new config if necessary
        if [ ! -f /config/config.xml ]
        then
          # We are generating a new config
          syncthing generate --config=/config
        fi

        # Apply the port every time (incase the user changes it and reboots)
        # sed -i  "s/<listenAddress>tcp.*/<listenAddress>tcp:\/\/0.0.0.0:${PORT_SYNCTHING}<\/listenAddress>/" /config/config.xml
        # sed -i  "s/<listenAddress>quic.*/<listenAddress>quic:\/\/0.0.0.0:${PORT_SYNCTHING}<\/listenAddress>/" /config/config.xml

        # # And if it's defaulted...
        # sed -i  "s/<<listenAddress>default<\/listenAddress>/<listenAddress>tcp:\/\/0.0.0.0:${PORT_SYNCTHING}<\/listenAddress>\n\t<listenAddress>quic:\/\/0.0.0.0:${PORT_SYNCTHING}<\/listenAddress>/" /config/config.xml

        # Ignore the fact that we have no password set
        # grep '<insecureAdminAccess>true</insecureAdminAccess>' /config/config.xml || sed -i  "s/<\/gui>/<insecureAdminAccess>true<\/insecureAdminAccess>\n\t<\/gui>/" /config/config.xml

        # Avoid foolish use of capital letters in default sync folder
        # sed -i  "s/\/storage\/elfstorage\/Sync/\/storage\/elfstorage\/syncthing/" /config/config.xml

      volumeMounts:
      - mountPath: /config
        name: config
      resources: *default_resources
      securityContext: *default_securitycontext

rdtclient:
  enabled: false
  hostname: elfhosted
  sso:
    enabled: true
  priorityClassName: tenant-bulk
  image:
    repository: ghcr.io/geek-cookbook/rdtclient
    tag: v2.0.40@sha256:d9333b820ab07a76f4ac1c7aec9e7f8b44f0bf9f8fc1f4d92dc184b34538d9bb
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-rdtclient"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists    
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /data/db
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-rdtclient-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-rdtclient
          optional: true

  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
  resources:
    requests:
      cpu: 10m
      memory: 10Mi
    limits:
      cpu: 1
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap

jdownloader:
  enabled: false
  hostname: elfhosted
  runtimeClassName: kata
  priorityClassName: tenant-bulk
  image:
    repository: jlesage/jdownloader-2
    tag: v23.11.2
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-jdownloader"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: node-role.elfhosted.com/download
            operator: Exists
  tolerations:
  - key: node-role.elfhosted.com/download
    operator: Exists    
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    # runAsUser: 568
    # runAsGroup: 568
    fsGroup: 568 # need this so that the bootstrap can run
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  env:
    JDOWNLOADER_HEADLESS: 1
    APP_NICENESS: 19
  envFrom:
  - configMapRef:
      name: jdownloader-config
  persistence:
    config:
      enabled: true
      type: custom
      mountPath: /config
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-jdownloader-ssd
    elfstorage:
      enabled: true # always enabled
      type: custom
      volumeSpec:
        persistentVolumeClaim:
          claimName: elfstorage
      mountPath: /output
      subPath: downloads/completed/jdownloader
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-jdownloader
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
      ports:
        http:
          port: 9898
  resources:
    requests:
      cpu: 10m
      memory: 10Mi
    limits:
      cpu: 0.5
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap
  additionalContainers:
    podinfo:
      image: stefanprodan/podinfo # used to run probes from gatus

nextcloud:
  enabled: false

miniflux:
  enabled: false
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/miniflux
    tag: 2.0.51
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-miniflux,miniflux-config"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 512Mi
    limits:
      cpu: 1500m # if par threads is 1, this leaves 0.5cpu for downloading
      memory: 1Gi
  envFrom:
  - configMapRef:
      name: miniflux-config
  postgresql:
    enabled: true
    nameOverride: miniflux-postgresql
    commonAnnotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-miniflux"
    auth:
      username: miniflux
      password: miniflux
      database: miniflux
      postgresPassword: miniflux
    primary:
      initContainers: *bootstrap_migrate_db
      persistence:
        enabled: true
        existingClaim: config-miniflux-ssd
        subPath: database
      resources:
        requests:
          cpu: 5m
          memory: 1Gi
        limits:
          cpu: 2
          memory: 1024Mi
      containerSecurityContext:
        enabled: true
        seccompProfile:
          type: RuntimeDefault
        runAsUser: 568
        runAsGroup: 568
      podSecurityContext:
        enabled: true
        runAsUser: 568
        runAsGroup: 568
        fsGroup: 568
      extraVolumeMounts:
      - mountPath: /opt/bitnami/postgresql/conf/
        name: conf
      - mountPath: /opt/bitnami/postgresql/tmp/
        name: tmp
      extraVolumes:
      - name: conf
        emptyDir:
          sizeLimit: 1Gi
      - name: tmp
        emptyDir:
          sizeLimit: 1Gi
      - name: elfstorage
        persistentVolumeClaim:
          claimName: elfstorage
      - name: confighdd
        persistentVolumeClaim:
          claimName: config-miniflux
      sidecars:
        - name: backup-database
          image: *tooling_image
          env:
            - name: POSTGRES_PASSWORD
              value: miniflux
            - name: POSTGRES_DATABASE
              value: miniflux
            - name: POSTGRES_USER
              value: miniflux
          volumeMounts:
          - mountPath: /backup
            name: elfstorage
            subPath: backup/miniflux
          command:
          - /usr/bin/dumb-init
          - /bin/bash
          - -c
          - |

            set +e # for debug
            sleep 2m # give postgres time to start up
            while true
            do
              now=$(date +"%s_%Y-%m-%d")
              PGPASSWORD=$POSTGRES_PASSWORD pg_dump -U $POSTGRES_USER -h localhost -d $POSTGRES_DATABASE -F c -f /backup/${now}_${POSTGRES_DATABASE}.psql
              sleep 1d
            done

joplinserver:
  enabled: false
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/geek-cookbook/joplin-server
    tag: v2.13.5@sha256:409c8ed129960d2b7d751452c94d9b1a2d85b5081fe164cd04401ac3f3293a19
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-joplinserver,joplinserver-config"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false # breaks migrations
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 512Mi
    limits:
      cpu: 1500m # if par threads is 1, this leaves 0.5cpu for downloading
      memory: 1Gi
  envFrom:
  - configMapRef:
      name: joplinserver-config
  persistence:
    config:
      enabled: true
      type: custom
      mountPath: /config
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-joplinserver
      subPath: data
  postgresql:
    enabled: true
    nameOverride: joplinserver-postgresql
    commonAnnotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-joplinserver"
    auth:
      username: joplinserver
      password: joplinserver
      database: joplinserver
      postgresPassword: joplinserver
    primary:
      persistence:
        enabled: true
        existingClaim: config-joplinserver
        subPath: database
      resources:
        requests:
          cpu: 5m
          memory: 1Gi
        limits:
          cpu: 2
          memory: 1024Mi
      containerSecurityContext:
        enabled: true
        seccompProfile:
          type: RuntimeDefault
        runAsUser: 568
        runAsGroup: 568
      podSecurityContext:
        enabled: true
        runAsUser: 568
        runAsGroup: 568
        fsGroup: 568
      extraVolumeMounts:
      - mountPath: /opt/bitnami/postgresql/conf/
        name: conf
      - mountPath: /opt/bitnami/postgresql/tmp/
        name: tmp
      extraVolumes:
      - name: conf
        emptyDir:
          sizeLimit: 1Gi
      - name: tmp
        emptyDir:
          sizeLimit: 1Gi
      - name: elfstorage
        persistentVolumeClaim:
          claimName: elfstorage
      sidecars:
        - name: backup-database
          image: *tooling_image
          env:
            - name: POSTGRES_PASSWORD
              value: joplinserver
            - name: POSTGRES_DATABASE
              value: joplinserver
            - name: POSTGRES_USER
              value: joplin
          volumeMounts:
          - mountPath: /backup
            name: elfstorage
            subPath: backup/miniflux
          command:
          - /usr/bin/dumb-init
          - /bin/bash
          - -c
          - |

            set +e # for debug
            sleep 2m # give postgres time to start up
            while true
            do
              now=$(date +"%s_%Y-%m-%d")
              PGPASSWORD=$POSTGRES_PASSWORD pg_dump -U $POSTGRES_USER -h localhost -d $POSTGRES_DATABASE -F c -f /backup/${now}_${POSTGRES_DATABASE}.psql
              sleep 1d
            done

tdarr:
  enabled: false
  priorityClassName: tenant-bulk
  image:
    repository: ghcr.io/haveagitgat/tdarr
    tag: 2.17.01
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-tdarr"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false
    privileged: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    # runAsUser: 568
    # runAsGroup: 568
    fsGroup: 568 # need this so that the bootstrap can run
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  env:
    PUID: 568
    PGID: 109 # for access to the DRI
    inContainer: "true"
    internalNode: "true"
    nodeName: elfnode
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /app/server
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-tdarr-ssd
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-tdarr
          optional: true
    render-device:
      enabled: "true"
      type: hostPath
      hostPath: "/dev/dri/renderD128"
      mountPath: "/dev/dri/renderD128"
    transcode:
      enabled: true
      type: emptyDir
      mountPath: /transcode
      sizeLimit: 200Gi # Don't allow > 200GB in transcoding files
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
      ports:
        http:
          port: 8265
  resources:
    requests:
      cpu: 150m
      memory: 500Mi
    limits:
      cpu: 250m # deliberately hobble the CPU in favor of GPU transcoding
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap

homepage:
  enabled: false
  priorityClassName: tenant-normal
  image:
    repository: ghcr.io/gethomepage/homepage
    tag: v0.8.3
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-homepage,homepage-config,homepage-env"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false
    privileged: true
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    # runAsUser: 568
    # runAsGroup: 568
    fsGroup: 568 # need this so that the bootstrap can run
    fsGroupChangePolicy: "OnRootMismatch"
  serviceAccount:
    create: true
    name: homepage
  automountServiceAccountToken: true
  env:
    PUID: 568
    PGID: 568
  envFrom:
  - configMapRef:
      name: elfbot-homepage
      optional: true
  - configMapRef:
      name: homepage-env
      optional: true      
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /app/config
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-homepage-ssd
    config-default:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: homepage-config
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-homepage
          optional: true
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
      ports:
        http:
          port: 3000
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 250m # deliberately hobble the CPU in favor of GPU transcoding
      memory: 1Gi
  initContainers:
    bootstrap: *bootstrap
    copy-example-config:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        mkdir -p /app/config/user-change-these/
        touch /app/config/user-change-these/JELLYFIN_KEY
        touch /app/config/user-change-these/PLEX_KEY
        touch /app/config/user-change-these/EMBY_KEY
        touch /app/config/user-change-these/NAVIDROME_USER
        touch /app/config/user-change-these/NAVIDROME_TOKEN
        touch /app/config/user-change-these/NAVIDROME_SALT
        touch /app/config/user-change-these/CALIBREWEB_USERNAME
        touch /app/config/user-change-these/CALIBREWEB_PASSWORD
        touch /app/config/user-change-these/KOMGA_USERNAME
        touch /app/config/user-change-these/KOMGA_PASSWORD
        touch /app/config/user-change-these/KAVITA_USERNAME
        touch /app/config/user-change-these/KAVITA_PASSWORD
        touch /app/config/user-change-these/AUDIOBOOKSHELF_KEY
        touch /app/config/user-change-these/OMBI_KEY
        touch /app/config/user-change-these/OVERSEERR_KEY
        touch /app/config/user-change-these/JELLYSEERR_KEY
        touch /app/config/user-change-these/TAUTULLI_KEY
        touch /app/config/user-change-these/XTEVE_USERNAME
        touch /app/config/user-change-these/XTEVE_PASSWORD
        touch /app/config/user-change-these/AUTOBRR_KEY
        touch /app/config/user-change-these/MINIFLUX_KEY
        touch /app/config/user-change-these/UPTIMEKUMA_SLUG
        touch /app/config/user-change-these/GOTIFY_KEY

        # If we don't already have an example config, create one
        if [ ! -f /app/config/dont-overwrite-me ];
        then
          cp /bootstrap/* /app/config/
        fi
      volumeMounts:
      - mountPath: /app/config
        name: config
      - name: config-default
        mountPath: "/bootstrap/"
      securityContext:
        seccompProfile:
          type: RuntimeDefault
        readOnlyRootFilesystem: true


wallabag:
  enabled: false
  priorityClassName: tenant-normal
  image:
    repository: stefanprodan/podinfo
    tag: latest
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-wallabag,wallabag-config"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: false
    privileged: false
  runtimeClassName: kata    
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    fsGroup: 568 # for the mounted volumes 
  persistence:
    config:
      enabled: true
      type: custom
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-wallabag-ssd
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
      ports:
        http:
          port: 8000
  resources:
    requests:
      cpu: 10m
      memory: 32Mi
    limits:
      cpu: 100m 
      memory: 1Gi
  additionalContainers:
    ui:
      image: ghcr.io/geek-cookbook/wallabag:2.6.7@sha256:0b35b55f7938fd4c983537d82248209bcc77878b5bba98583173c3b750f21c93
      volumeMounts:
      - mountPath: /var/www/wallabag/data
        name: config
        subPath: data
      - mountPath: /var/www/wallabag/images
        name: config
        subPath: images
      envFrom:
      - configMapRef:
          name: elfbot-wallbag
          optional: true
      - configMapRef:
          name: wallabag-config
      securityContext:
        seccompProfile:
          type: RuntimeDefault           
        allowPrivilegeEscalation: false
      resources:
        requests:
          cpu: 1m
          memory: 100Mi
        limits:
          cpu: 500m 
          memory: 200Mi        

autoscan:
  enabled: false
  image:
    repository: ghcr.io/geek-cookbook/autoscan
    tag: 1.4.0@sha256:814ee8a40831a44227cb362190d8b105797c608224ae2ef73a4c9058a9f102d3
  priorityClassName: tenant-normal
  controller:
    annotations:
      configmap.reloader.stakater.com/reload: "elfbot-all,storage-changed,elfbot-autoscan"
  securityContext:
    seccompProfile:
      type: RuntimeDefault
    readOnlyRootFilesystem: true # doesn't work because the node modules in /app try to create files
  podSecurityContext:
    seccompProfile:
      type: RuntimeDefault
    runAsUser: 568
    runAsGroup: 568
    fsGroup: 568
    fsGroupChangePolicy: "OnRootMismatch"
  automountServiceAccountToken: false
  resources:
    requests:
      cpu: 10m
      memory: 16Mi
    limits:
      cpu: 100m
      memory: 1024Mi
  ingress:
    main:
      enabled: false
  service:
    main:
      enabled: true # necessary for probes
      ports:
        http:
          port: 3030 
  persistence:
    <<: *appmounts
    config:
      enabled: true
      type: custom
      mountPath: /config/
      volumeSpec:
        persistentVolumeClaim:
          claimName: config-autoscan-ssd
    example-config:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: autoscan-config
    elfbot:
      enabled: "true"
      type: "custom"
      volumeSpec:
        configMap:
          name: elfbot-autoscan
          optional: true

  initContainers:
    bootstrap: *bootstrap
    copy-example-config:
      image: *tooling_image
      imagePullPolicy: IfNotPresent
      command:
      - /bin/bash
      - -c
      - |
        set -x
        set -e

        # If we don't already have an example config, create one
        if [ ! -f /config/config.yml ];
        then
          cp /bootstrap/config.yml /config/
        fi
      volumeMounts:
      - mountPath: /config
        name: config
      - name: example-config
        mountPath: "/bootstrap/"
      securityContext:
        seccompProfile:
          type: RuntimeDefault
        readOnlyRootFilesystem: true

# This file must end on a newline
